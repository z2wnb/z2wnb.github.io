<!DOCTYPE html>


<html lang="en">


<head>
  <meta charset="utf-8" />
    
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
  <title>
     
  </title>
  <meta name="generator" content="hexo-theme-ayer">
  
  <link rel="shortcut icon" href="/images/logo.png" />
  
  
<link rel="stylesheet" href="/dist/main.css">

  
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Shen-Yu/cdn/css/remixicon.min.css">

  
<link rel="stylesheet" href="/css/custom.css">

  
  
<script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script>

  
  

  

<link rel="alternate" href="/atom.xml" title="Z2WNB" type="application/atom+xml">
</head>

</html>

<body>
  <div id="app">
    
      
      <canvas width="1777" height="841"
        style="position: fixed; left: 0px; top: 0px; z-index: 99999; pointer-events: none;"></canvas>
      
    <main class="content on">
      
<section class="cover">
    
      
      <a class="forkMe" href="https://github.com/z2wnb/z2wnb.github.io"
        target="_blank"><img width="149" height="149" src="/images/forkme.png"
          class="attachment-full size-full" alt="Fork me on GitHub" data-recalc-dims="1"></a>
    
  <div class="cover-frame">
    <div class="bg-box">
      <img src="/images/cover1.jpg" alt="image frame" />
    </div>
    <div class="cover-inner text-center text-white">
      <h1><a href="/">Z2WNB</a></h1>
      <div id="subtitle-box">
        
        <span id="subtitle"></span>
        
      </div>
      <div>
        
      </div>
    </div>
  </div>
  <div class="cover-learn-more">
    <a href="javascript:void(0)" class="anchor"><i class="ri-arrow-down-line"></i></a>
  </div>
</section>



<script src="https://cdn.jsdelivr.net/npm/typed.js@2.0.11/lib/typed.min.js"></script>


<!-- Subtitle -->

  <script>
    try {
      var typed = new Typed("#subtitle", {
        strings: ['面朝大海，春暖花开', '愿你一生努力，一生被爱', '想要的都拥有，得不到的都释怀'],
        startDelay: 0,
        typeSpeed: 200,
        loop: true,
        backSpeed: 100,
        showCursor: true
      });
    } catch (err) {
      console.log(err)
    }
  </script>
  
<div id="main">
  <section class="outer">
  
  

<div class="notice" style="margin-top:50px">
    <i class="ri-heart-fill"></i>
    <div class="notice-content" id="broad"></div>
</div>
<script type="text/javascript">
    fetch('https://v1.hitokoto.cn')
        .then(response => response.json())
        .then(data => {
            document.getElementById("broad").innerHTML = data.hitokoto;
        })
        .catch(console.error)
</script>

<style>
    .notice {
        padding: 20px;
        border: 1px dashed #e6e6e6;
        color: #969696;
        position: relative;
        display: inline-block;
        width: 100%;
        background: #fbfbfb50;
        border-radius: 10px;
    }

    .notice i {
        float: left;
        color: #999;
        font-size: 16px;
        padding-right: 10px;
        vertical-align: middle;
        margin-top: -2px;
    }

    .notice-content {
        display: initial;
        vertical-align: middle;
    }
</style>
  
  <article class="articles">
    
    
    
    
    <article
  id="post-Tensorflow学习笔记"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2019/02/20/Tensorflow%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"
    >Tensorflow学习笔记</a> 
</h2>
 

    </header>
     
    <div class="article-meta">
      <a href="/2019/02/20/Tensorflow%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" class="article-date">
  <time datetime="2019-02-20T09:20:42.000Z" itemprop="datePublished">2019-02-20</time>
</a>    
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h1 id="Tensorflow-学习笔记"><a href="#Tensorflow-学习笔记" class="headerlink" title="Tensorflow 学习笔记"></a>Tensorflow 学习笔记</h1><h2 id="1-设置tensorflow输出日志级别"><a href="#1-设置tensorflow输出日志级别" class="headerlink" title="1. 设置tensorflow输出日志级别"></a>1. 设置tensorflow输出日志级别</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.environ[<span class="string">&quot;TF_CPP_MIN_LOG_LEVEL&quot;</span>] = <span class="string">&quot;2&quot;</span></span><br></pre></td></tr></table></figure>

<h2 id="2-tf-argmax-函数"><a href="#2-tf-argmax-函数" class="headerlink" title="2. tf.argmax()函数"></a>2. tf.argmax()函数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">A = [[<span class="number">1</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]]</span><br><span class="line">B = [[<span class="number">1</span>, <span class="number">3</span>, <span class="number">4</span>], [<span class="number">2</span>, <span class="number">4</span>, <span class="number">1</span>]]</span><br><span class="line"></span><br><span class="line"><span class="comment"># tf.argmax(y_, 1) 取的是行的最大值对应的下标的索引</span></span><br><span class="line"><span class="comment"># tf.argmax(y_, 0) 取的是列的最大值对应的下标的索引</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    print(sess.run(tf.argmax(A, <span class="number">1</span>)))</span><br><span class="line">    print(sess.run(tf.argmax(B, <span class="number">0</span>)))</span><br></pre></td></tr></table></figure>
<p>运行结果：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[4]</span><br><span class="line">[1 1 0]</span><br></pre></td></tr></table></figure>
<h2 id="3-tf-reduce-mean-函数"><a href="#3-tf-reduce-mean-函数" class="headerlink" title="3. tf.reduce_mean() 函数"></a>3. tf.reduce_mean() 函数</h2><ul>
<li>函数用于计算张量tensor沿着指定的数轴（tensor的某一维度）上的的平均值，主要用作降维或者计算tensor（图像）的平均值。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">reduce_mean(input_tensor,</span><br><span class="line">                axis=<span class="literal">None</span>,</span><br><span class="line">                keep_dims=<span class="literal">False</span>,</span><br><span class="line">                name=<span class="literal">None</span>,</span><br><span class="line">                reduction_indices=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li>第一个参数input_tensor： 输入的待降维的tensor;</li>
<li>第二个参数axis： 指定的轴，如果不指定，则计算所有元素的均值;</li>
<li>第三个参数keep_dims：是否降维度，设置为True，输出的结果保持输入tensor的形状，设置为False，输出结果会降低维度;</li>
<li>第四个参数name： 操作的名称;</li>
<li>第五个参数 reduction_indices：在以前版本中用来指定轴，已弃用;</li>
</ul>
<h2 id="4-滑动平均-ExponentialMovingAverage"><a href="#4-滑动平均-ExponentialMovingAverage" class="headerlink" title="4. 滑动平均-ExponentialMovingAverage()"></a>4. 滑动平均-ExponentialMovingAverage()</h2><ul>
<li>神经网络的优化函数</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY, global_step)</span><br></pre></td></tr></table></figure>

<h2 id="5-variables-to-restore-函数"><a href="#5-variables-to-restore-函数" class="headerlink" title="5. variables_to_restore()函数"></a>5. variables_to_restore()函数</h2><blockquote>
<p>是TensorFlow为滑动平均值提供。之前，也介绍过通过使用滑动平均值可以让神经网络模型更加的健壮。我们也知道，其实在TensorFlow中，变量的滑动平均值都是由影子变量所维护的，如果你想要获取变量的滑动平均值需要获取的是影子变量而不是变量本身。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">variable_averages = tf.train.ExponentialMovingAverage(mnist_train.MOVING_AVERAGE_DECAY)</span><br><span class="line">variables_to_restore = variable_averages.variables_to_restore()</span><br></pre></td></tr></table></figure> 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Tensorflow/" rel="tag">Tensorflow</a></li></ul>

    </footer>
  </div>

    
 
   
</article>

    
    <article
  id="post-GNN论文列表"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2019/02/15/GNN%E8%AE%BA%E6%96%87%E5%88%97%E8%A1%A8/"
    >GNN论文列表</a> 
</h2>
 

    </header>
     
    <div class="article-meta">
      <a href="/2019/02/15/GNN%E8%AE%BA%E6%96%87%E5%88%97%E8%A1%A8/" class="article-date">
  <time datetime="2019-02-15T12:36:20.000Z" itemprop="datePublished">2019-02-15</time>
</a>    
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h2 id="Must-read-papers-on-GNN"><a href="#Must-read-papers-on-GNN" class="headerlink" title="Must-read papers on GNN"></a>Must-read papers on GNN</h2><p>GNN: graph neural network</p>
<p>Contributed by Jie Zhou, Ganqu Cui and Zhengyan Zhang.</p>
<h3 id="Survey-papers"><a href="#Survey-papers" class="headerlink" title="Survey papers"></a>Survey papers</h3><ol>
<li><strong>Graph Neural Networks: A Review of Methods and Applications.</strong></li>
</ol>
<p><em>Jie Zhou, Ganqu Cui, Zhengyan Zhang, Cheng Yang, Zhiyuan Liu, Maosong Sun.</em> 2018. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1812.08434.pdf">paper</a></p>
<ol>
<li><strong>A Comprehensive Survey on Graph Neural Networks.</strong></li>
</ol>
<p><em>Zonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, Philip S. Yu.</em> 2019. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1901.00596.pdf">paper</a></p>
<ol>
<li><strong>Deep Learning on Graphs: A Survey.</strong></li>
</ol>
<p><em>Ziwei Zhang, Peng Cui, Wenwu Zhu.</em> 2018. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1812.04202.pdf">paper</a></p>
<ol>
<li><strong>Relational Inductive Biases, Deep Learning, and Graph Networks.</strong></li>
</ol>
<p><em>Battaglia, Peter W and Hamrick, Jessica B and Bapst, Victor and Sanchez-Gonzalez, Alvaro and Zambaldi, Vinicius and Malinowski, Mateusz and Tacchetti, Andrea and Raposo, David and Santoro, Adam and Faulkner, Ryan and others.</em> 2018. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1806.01261.pdf">paper</a></p>
<ol>
<li><strong>Geometric Deep Learning: Going beyond Euclidean data.</strong></li>
</ol>
<p><em>Bronstein, Michael M and Bruna, Joan and LeCun, Yann and Szlam, Arthur and Vandergheynst, Pierre.</em> IEEE SPM 2017. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1611.08097.pdf">paper</a></p>
<ol>
<li><strong>Computational Capabilities of Graph Neural Networks.</strong></li>
</ol>
<p><em>Scarselli, Franco and Gori, Marco and Tsoi, Ah Chung and Hagenbuchner, Markus and Monfardini, Gabriele.</em> IEEE TNN 2009. <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=4703190">paper</a></p>
<ol>
<li><strong>Neural Message Passing for Quantum Chemistry.</strong></li>
</ol>
<p><em>Gilmer, Justin and Schoenholz, Samuel S and Riley, Patrick F and Vinyals, Oriol and Dahl, George E.</em> 2017. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1704.01212.pdf">paper</a></p>
<ol>
<li><strong>Non-local Neural Networks.</strong></li>
</ol>
<p><em>Wang, Xiaolong and Girshick, Ross and Gupta, Abhinav and He, Kaiming.</em> CVPR 2018. <a target="_blank" rel="noopener" href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Wang_Non-Local_Neural_Networks_CVPR_2018_paper.pdf">paper</a></p>
<ol>
<li><strong>The Graph Neural Network Model.</strong></li>
</ol>
<p><em>Scarselli, Franco and Gori, Marco and Tsoi, Ah Chung and Hagenbuchner, Markus and Monfardini, Gabriele.</em> IEEE TNN 2009. <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=4700287">paper</a></p>
<h3 id="Models"><a href="#Models" class="headerlink" title="Models"></a>Models</h3><ol>
<li><strong>A new model for learning in graph domains.</strong></li>
</ol>
<p><em>Marco Gori, Gabriele Monfardini, Franco Scarselli.</em> IJCNN 2005. <a target="_blank" rel="noopener" href="https://www.researchgate.net/profile/Franco_Scarselli/publication/4202380_A_new_model_for_earning_in_raph_domains/links/0c9605188cd580504f000000.pdf">paper</a></p>
<ol>
<li><strong>Graph Neural Networks for Ranking Web Pages.</strong></li>
</ol>
<p><em>Franco Scarselli, Sweah Liang Yong, Marco Gori, Markus Hagenbuchner, Ah Chung Tsoi, Marco Maggini.</em> WI 2005. <a target="_blank" rel="noopener" href="https://www.researchgate.net/profile/Franco_Scarselli/publication/221158677_Graph_Neural_Networks_for_Ranking_Web_Pages/links/0c9605188cd5090ede000000/Graph-Neural-Networks-for-Ranking-Web-Pages.pdf">paper</a></p>
<ol>
<li><strong>Gated Graph Sequence Neural Networks.</strong></li>
</ol>
<p><em>Yujia Li, Daniel Tarlow, Marc Brockschmidt, Richard Zemel.</em> ICLR 2016. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1511.05493.pdf">paper</a></p>
<ol>
<li><strong>Geometric deep learning on graphs and manifolds using mixture model cnns.</strong></li>
</ol>
<p><em>Federico Monti, Davide Boscaini, Jonathan Masci, Emanuele Rodol�, Jan Svoboda, Michael M. Bronstein.</em> CVPR 2017. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1611.08402.pdf">paper</a></p>
<ol>
<li><strong>Spectral Networks and Locally Connected Networks on Graphs.</strong></li>
</ol>
<p><em>Joan Bruna, Wojciech Zaremba, Arthur Szlam, Yann LeCun.</em> ICLR 2014. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1312.6203.pdf">paper</a></p>
<ol>
<li><strong>Deep Convolutional Networks on Graph-Structured Data.</strong></li>
</ol>
<p><em>Mikael Henaff, Joan Bruna, Yann LeCun.</em> 2015. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1506.05163.pdf">paper</a></p>
<ol>
<li><strong>Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering.</strong></li>
</ol>
<p><em>Micha�l Defferrard, Xavier Bresson, Pierre Vandergheynst.</em> NIPS 2016. <a target="_blank" rel="noopener" href="http://papers.nips.cc/paper/6081-convolutional-neural-networks-on-graphs-with-fast-localized-spectral-filtering.pdf">paper</a></p>
<ol>
<li><strong>Learning Convolutional Neural Networks for Graphs.</strong></li>
</ol>
<p><em>Mathias Niepert, Mohamed Ahmed, Konstantin Kutzkov.</em> ICML 2016. <a target="_blank" rel="noopener" href="http://proceedings.mlr.press/v48/niepert16.pdf">paper</a></p>
<ol>
<li><strong>Semi-Supervised Classification with Graph Convolutional Networks.</strong></li>
</ol>
<p><em>Thomas N. Kipf, Max Welling.</em> ICLR 2017. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1609.02907.pdf">paper</a></p>
<ol>
<li><strong>Graph Attention Networks.</strong></li>
</ol>
<p><em>Petar Velickovic, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, Yoshua Bengio.</em> ICLR 2018. <a target="_blank" rel="noopener" href="https://mila.quebec/wp-content/uploads/2018/07/d1ac95b60310f43bb5a0b8024522fbe08fb2a482.pdf">paper</a></p>
<ol>
<li><strong>Deep Sets.</strong></li>
</ol>
<p><em>Manzil Zaheer, Satwik Kottur, Siamak Ravanbakhsh, Barnabas Poczos, Ruslan Salakhutdinov, Alexander Smola.</em> NIPS 2017. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1703.06114.pdf">paper</a></p>
<ol>
<li><strong>Graph Partition Neural Networks for Semi-Supervised Classification.</strong></li>
</ol>
<p><em>Renjie Liao, Marc Brockschmidt, Daniel Tarlow, Alexander L. Gaunt, Raquel Urtasun, Richard Zemel.</em> 2018. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1803.06272.pdf">paper</a></p>
<ol>
<li><strong>Covariant Compositional Networks For Learning Graphs.</strong></li>
</ol>
<p><em>Risi Kondor, Hy Truong Son, Horace Pan, Brandon Anderson, Shubhendu Trivedi.</em> 2018. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1801.02144.pdf">paper</a></p>
<ol>
<li><strong>Modeling Relational Data with Graph Convolutional Networks.</strong></li>
</ol>
<p><em>Michael Schlichtkrull, Thomas N. Kipf, Peter Bloem, Rianne van den Berg, Ivan Titov, Max Welling.</em> ESWC 2018. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1703.06103.pdf">paper</a></p>
<ol>
<li><strong>Stochastic Training of Graph Convolutional Networks with Variance Reduction.</strong></li>
</ol>
<p><em>Jianfei Chen, Jun Zhu, Le Song.</em> ICML 2018. <a target="_blank" rel="noopener" href="http://www.scipaper.net/uploadfile/2018/0716/20180716100330880.pdf">paper</a></p>
<ol>
<li><strong>Learning Steady-States of Iterative Algorithms over Graphs.</strong></li>
</ol>
<p><em>Hanjun Dai, Zornitsa Kozareva, Bo Dai, Alex Smola, Le Song.</em> ICML 2018. <a target="_blank" rel="noopener" href="http://proceedings.mlr.press/v80/dai18a/dai18a.pdf">paper</a></p>
<ol>
<li><strong>Deriving Neural Architectures from Sequence and Graph Kernels.</strong></li>
</ol>
<p><em>Tao Lei, Wengong Jin, Regina Barzilay, Tommi Jaakkola.</em> ICML 2017. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1705.09037.pdf">paper</a></p>
<ol>
<li><strong>Adaptive Graph Convolutional Neural Networks.</strong></li>
</ol>
<p><em>Ruoyu Li, Sheng Wang, Feiyun Zhu, Junzhou Huang.</em> AAAI 2018. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1801.03226.pdf">paper</a></p>
<ol>
<li><strong>Graph-to-Sequence Learning using Gated Graph Neural Networks.</strong></li>
</ol>
<p><em>Daniel Beck, Gholamreza Haffari, Trevor Cohn.</em> ACL 2018. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1806.09835.pdf">paper</a></p>
<ol>
<li><strong>Deeper Insights into Graph Convolutional Networks for Semi-Supervised Learning.</strong></li>
</ol>
<p><em>Qimai Li, Zhichao Han, Xiao-Ming Wu.</em> AAAI 2018. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1801.07606.pdf">paper</a></p>
<ol>
<li><strong>Graphical-Based Learning Environments for Pattern Recognition.</strong></li>
</ol>
<p><em>Franco Scarselli, Ah Chung Tsoi, Marco Gori, Markus Hagenbuchner.</em> SSPR/SPR 2004. <a target="_blank" rel="noopener" href="https://link.springer.com/content/pdf/10.1007%2F978-3-540-27868-9_4.pdf">paper</a></p>
<ol>
<li><strong>A Comparison between Recursive Neural Networks and Graph Neural Networks.</strong></li>
</ol>
<p><em>Vincenzo Di Massa, Gabriele Monfardini, Lorenzo Sarti, Franco Scarselli, Marco Maggini, Marco Gori.</em> IJCNN 2006. <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=1716174">paper</a></p>
<ol>
<li><strong>Graph Neural Networks for Object Localization.</strong></li>
</ol>
<p><em>Gabriele Monfardini, Vincenzo Di Massa, Franco Scarselli, Marco Gori.</em> ECAI 2006. <a target="_blank" rel="noopener" href="http://ebooks.iospress.nl/volumearticle/2775">paper</a></p>
<ol>
<li><strong>Knowledge-Guided Recurrent Neural Network Learning for Task-Oriented Action Prediction.</strong></li>
</ol>
<p><em>Liang Lin, Lili Huang, Tianshui Chen, Yukang Gan, Hui Cheng.</em> ICME 2017. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1707.04677.pdf">paper</a></p>
<ol>
<li><strong>Semantic Object Parsing with Graph LSTM.</strong></li>
</ol>
<p><em>Xiaodan LiangXiaohui ShenJiashi FengLiang Lin, Shuicheng Yan.</em> ECCV 2016. <a target="_blank" rel="noopener" href="https://link.springer.com/content/pdf/10.1007%2F978-3-319-46448-0_8.pdf">paper</a></p>
<ol>
<li><strong>CelebrityNet: A Social Network Constructed from Large-Scale Online Celebrity Images.</strong></li>
</ol>
<p><em>Li-Jia Li, David A. Shamma, Xiangnan Kong, Sina Jafarpour, Roelof Van Zwol, Xuanhui Wang.</em> TOMM 2015. <a target="_blank" rel="noopener" href="https://dl.acm.org/ft_gateway.cfm?id=2801125&ftid=1615097&dwn=1&CFID=38275959&CFTOKEN=6938a464cf972252-DF065FDC-9FED-EB68-3528017EA04F0D29">paper</a></p>
<ol>
<li><strong>Inductive Representation Learning on Large Graphs.</strong></li>
</ol>
<p><em>William L. Hamilton, Rex Ying, Jure Leskovec.</em> NIPS 2017. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1706.02216.pdf">paper</a></p>
<ol>
<li><strong>Graph Classification using Structural Attention.</strong></li>
</ol>
<p><em>John Boaz Lee, Ryan Rossi, Xiangnan Kong.</em> KDD 18. <a target="_blank" rel="noopener" href="https://dl.acm.org/ft_gateway.cfm?id=3219980&ftid=1988883&dwn=1&CFID=38275959&CFTOKEN=6938a464cf972252-DF065FDC-9FED-EB68-3528017EA04F0D29">paper</a></p>
<ol>
<li><strong>Adversarial Attacks on Neural Networks for Graph Data.</strong></li>
</ol>
<p><em>Daniel Z�gner, Amir Akbarnejad, Stephan G�nnemann.</em> KDD 18. <a target="_blank" rel="noopener" href="http://delivery.acm.org/10.1145/3230000/3220078/p2847-zugner.pdf?ip=101.5.139.169&id=3220078&acc=ACTIVE%20SERVICE&key=BF85BBA5741FDC6E.587F3204F5B62A59.4D4702B0C3E38B35.4D4702B0C3E38B35&__acm__=1545706391_e7484be677293ffb5f18b39ce84a0df9">paper</a></p>
<ol>
<li><strong>Large-Scale Learnable Graph Convolutional Networks.</strong></li>
</ol>
<p><em>Hongyang Gao, Zhengyang Wang, Shuiwang Ji.</em> KDD 18. <a target="_blank" rel="noopener" href="http://delivery.acm.org/10.1145/3220000/3219947/p1416-gao.pdf?ip=101.5.139.169&id=3219947&acc=ACTIVE%20SERVICE&key=BF85BBA5741FDC6E.587F3204F5B62A59.4D4702B0C3E38B35.4D4702B0C3E38B35&__acm__=1545706457_bb20316c7ce038aefb97afcf4ef9668b">paper</a></p>
<ol>
<li><strong>Contextual Graph Markov Model: A Deep and Generative Approach to Graph Processing.</strong></li>
</ol>
<p><em>Davide Bacciu, Federico Errica, Alessio Micheli.</em> ICML 2018. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1805.10636.pdf">paper</a></p>
<ol>
<li><strong>Diffusion-Convolutional Neural Networks.</strong></li>
</ol>
<p><em>James Atwood, Don Towsley.</em> NIPS 2016. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1511.02136.pdf">paper</a></p>
<ol>
<li><strong>Neural networks for relational learning: an experimental comparison.</strong></li>
</ol>
<p><em>Werner Uwents, Gabriele Monfardini, Hendrik Blockeel, Marco Gori, Franco Scarselli.</em> Machine Learning 2011. <a target="_blank" rel="noopener" href="https://link.springer.com/content/pdf/10.1007%2Fs10994-010-5196-5.pdf">paper</a></p>
<ol>
<li><strong>FastGCN: Fast Learning with Graph Convolutional Networks via Importance Sampling.</strong></li>
</ol>
<p><em>Jie Chen, Tengfei Ma, Cao Xiao.</em> ICLR 2018. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1801.10247.pdf">paper</a></p>
<ol>
<li><strong>Adaptive Sampling Towards Fast Graph Representation Learning.</strong></li>
</ol>
<p><em>Wenbing Huang, Tong Zhang, Yu Rong, Junzhou Huang.</em> NeurIPS 2018. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1809.05343.pdf">paper</a></p>
<ol>
<li><strong>Structure-Aware Convolutional Neural Networks.</strong></li>
</ol>
<p><em>Jianlong Chang, Jie Gu, Lingfeng Wang, Gaofeng Meng, Shiming Xiang, Chunhong Pan.</em> NeurIPS 2018. <a target="_blank" rel="noopener" href="http://papers.nips.cc/paper/7287-structure-aware-convolutional-neural-networks.pdf">paper</a></p>
<ol>
<li><strong>Bayesian Semi-supervised Learning with Graph Gaussian Processes.</strong></li>
</ol>
<p><em>Yin Cheng Ng, Nicol� Colombo, Ricardo Silva.</em> NeurIPS 2018. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1809.04379">paper</a></p>
<ol>
<li><strong>Mean-field theory of graph neural networks in graph partitioning.</strong></li>
</ol>
<p><em>Tatsuro Kawamoto, Masashi Tsubaki, Tomoyuki Obuchi.</em> NeurIPS 2018. <a target="_blank" rel="noopener" href="http://papers.nips.cc/paper/7689-mean-field-theory-of-graph-neural-networks-in-graph-partitioning.pdf">paper</a></p>
<ol>
<li><strong>Hierarchical Graph Representation Learning with Differentiable Pooling.</strong></li>
</ol>
<p><em>Zhitao Ying, Jiaxuan You, Christopher Morris, Xiang Ren, Will Hamilton, Jure Leskovec.</em> NeurIPS 2018. <a target="_blank" rel="noopener" href="https://papers.nips.cc/paper/7729-hierarchical-graph-representation-learning-with-differentiable-pooling.pdf">paper</a></p>
<ol>
<li><strong>How Powerful are Graph Neural Networks?</strong></li>
</ol>
<p><em>Keyulu Xu, Weihua Hu, Jure Leskovec, Stefanie Jegelka.</em> ICLR 2019. <a target="_blank" rel="noopener" href="https://openreview.net/pdf?id=ryGs6iA5Km">paper</a></p>
<ol>
<li><strong>Graph Capsule Convolutional Neural Networks.</strong></li>
</ol>
<p><em>Saurabh Verma, Zhi-Li Zhang.</em> ICML 2018 Workshop. <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1805.08090">paper</a></p>
<ol>
<li><strong>Capsule Graph Neural Network.</strong></li>
</ol>
<p><em>Zhang Xinyi, Lihui Chen.</em> ICLR 2019. <a target="_blank" rel="noopener" href="https://openreview.net/pdf?id=Byl8BnRcYm">paper</a></p>
<h3 id="Applications"><a href="#Applications" class="headerlink" title="Applications"></a>Applications</h3><ol>
<li><strong>Discovering objects and their relations from entangled scene representations.</strong></li>
</ol>
<p><em>David Raposo, Adam Santoro, David Barrett, Razvan Pascanu, Timothy Lillicrap, Peter Battaglia.</em> ICLR Workshop 2017. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1702.05068.pdf">paper</a></p>
<ol>
<li><strong>A simple neural network module for relational reasoning.</strong></li>
</ol>
<p><em>Adam Santoro, David Raposo, David G.T. Barrett, Mateusz Malinowski, Razvan Pascanu, Peter Battaglia, Timothy Lillicrap.</em> NIPS 2017. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1706.01427.pdf">paper</a></p>
<ol>
<li><strong>Attend, Infer, Repeat: Fast Scene Understanding with Generative Models.</strong></li>
</ol>
<p><em>S. M. Ali Eslami, Nicolas Heess, Theophane Weber, Yuval Tassa, David Szepesvari, Koray Kavukcuoglu, Geoffrey E. Hinton.</em> NIPS 2016. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1603.08575.pdf">paper</a></p>
<ol>
<li><strong>Beyond Categories: The Visual Memex Model for Reasoning About Object Relationships.</strong></li>
</ol>
<p><em>Tomasz Malisiewicz, Alyosha Efros.</em> NIPS 2009. <a target="_blank" rel="noopener" href="http://papers.nips.cc/paper/3647-beyond-categories-the-visual-memex-model-for-reasoning-about-object-relationships.pdf">paper</a></p>
<ol>
<li><strong>Understanding Kin Relationships in a Photo.</strong></li>
</ol>
<p><em>Siyu Xia, Ming Shao, Jiebo Luo, Yun Fu.</em> TMM 2012. <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6151163">paper</a></p>
<ol>
<li><strong>Graph-Structured Representations for Visual Question Answering.</strong></li>
</ol>
<p><em>Damien Teney, Lingqiao Liu, Anton van den Hengel.</em> CVPR 2017. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1609.05600.pdf">paper</a></p>
<ol>
<li><strong>Spatial Temporal Graph Convolutional Networks for Skeleton-Based Action Recognition.</strong></li>
</ol>
<p><em>Sijie Yan, Yuanjun Xiong, Dahua Lin.</em> AAAI 2018. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1801.07455.pdf">paper</a></p>
<ol>
<li><strong>Few-Shot Learning with Graph Neural Networks.</strong></li>
</ol>
<p><em>Victor Garcia, Joan Bruna.</em> ICLR 2018. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1711.04043.pdf">paper</a></p>
<ol>
<li><strong>The More You Know: Using Knowledge Graphs for Image Classification.</strong></li>
</ol>
<p><em>Kenneth Marino, Ruslan Salakhutdinov, Abhinav Gupta.</em> CVPR 2017. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1612.04844.pdf">paper</a></p>
<ol>
<li><strong>Zero-shot Recognition via Semantic Embeddings and Knowledge Graphs.</strong></li>
</ol>
<p><em>Xiaolong Wang, Yufei Ye, Abhinav Gupta.</em> CVPR 2018. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1803.08035.pdf">paper</a></p>
<ol>
<li><strong>Rethinking Knowledge Graph Propagation for Zero-Shot Learning.</strong></li>
</ol>
<p><em>Michael Kampffmeyer, Yinbo Chen, Xiaodan Liang, Hao Wang, Yujia Zhang, Eric P. Xing.</em> 2018. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1805.11724.pdf">paper</a></p>
<ol>
<li><strong>Interaction Networks for Learning about Objects, Relations and Physics.</strong></li>
</ol>
<p><em>Peter Battaglia, Razvan Pascanu, Matthew Lai, Danilo Rezende, Koray Kavukcuoglu.</em> NIPS 2016. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1612.00222.pdf">paper</a></p>
<ol>
<li><strong>A Compositional Object-Based Approach to Learning Physical Dynamics.</strong></li>
</ol>
<p><em>Michael B. Chang, Tomer Ullman, Antonio Torralba, Joshua B. Tenenbaum.</em> ICLR 2017. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1612.00341.pdf">paper</a></p>
<ol>
<li><strong>Visual Interaction Networks: Learning a Physics Simulator from Vide.o</strong> </li>
</ol>
<p><em>Nicholas Watters, Andrea Tacchetti, Th�ophane Weber, Razvan Pascanu, Peter Battaglia, Daniel Zoran.</em> NIPS 2017. <a target="_blank" rel="noopener" href="http://papers.nips.cc/paper/7040-visual-interaction-networks-learning-a-physics-simulator-from-video.pdf">paper</a></p>
<ol>
<li><strong>Relational neural expectation maximization: Unsupervised discovery of objects and their interactions.</strong></li>
</ol>
<p><em>Sjoerd van Steenkiste, Michael Chang, Klaus Greff, J�rgen Schmidhuber.</em> ICLR 2018. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1802.10353.pdf">paper</a></p>
<ol>
<li><strong>Graph networks as learnable physics engines for inference and control.</strong></li>
</ol>
<p><em>Alvaro Sanchez-Gonzalez, Nicolas Heess, Jost Tobias Springenberg, Josh Merel, Martin Riedmiller, Raia Hadsell, Peter Battaglia.</em> ICML 2018. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1806.01242.pdf">paper</a></p>
<ol>
<li><strong>Learning Multiagent Communication with Backpropagation.</strong></li>
</ol>
<p><em>Sainbayar Sukhbaatar, Arthur Szlam, Rob Fergus.</em> NIPS 2016. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1605.07736.pdf">paper</a></p>
<ol>
<li><strong>VAIN: Attentional Multi-agent Predictive Modeling.</strong></li>
</ol>
<p><em>Yedid Hoshen.</em> NIPS 2017 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1706.06122.pdf">paper</a></p>
<ol>
<li><strong>Neural Relational Inference for Interacting Systems.</strong></li>
</ol>
<p><em>Thomas Kipf, Ethan Fetaya, Kuan-Chieh Wang, Max Welling, Richard Zemel.</em> ICML 2018. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1802.04687.pdf">paper</a></p>
<ol>
<li><strong>Translating Embeddings for Modeling Multi-relational Data.</strong></li>
</ol>
<p><em>Antoine Bordes, Nicolas Usunier, Alberto Garcia-Duran, Jason Weston, Oksana Yakhnenko.</em> NIPS 2013. <a target="_blank" rel="noopener" href="http://papers.nips.cc/paper/5071-translating-embeddings-for-modeling-multi-relational-data.pdf">paper</a></p>
<ol>
<li><strong>Representation learning for visual-relational knowledge graphs.</strong></li>
</ol>
<p><em>Daniel O�oro-Rubio, Mathias Niepert, Alberto Garc�a-Dur�n, Roberto Gonz�lez, Roberto J. L�pez-Sastre.</em> 2017. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1709.02314.pdf">paper</a></p>
<ol>
<li><strong>Knowledge Transfer for Out-of-Knowledge-Base Entities : A Graph Neural Network Approach.</strong></li>
</ol>
<p><em>Takuo Hamaguchi, Hidekazu Oiwa, Masashi Shimbo, Yuji Matsumoto.</em> IJCAI 2017. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1706.05674.pdf">paper</a></p>
<ol>
<li><strong>Representation Learning on Graphs with Jumping Knowledge Networks.</strong></li>
</ol>
<p><em>Keyulu Xu, Chengtao Li, Yonglong Tian, Tomohiro Sonobe, Ken-ichi Kawarabayashi, Stefanie Jegelka.</em> ICML 2018. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1806.03536.pdf">paper</a></p>
<ol>
<li><strong>Multi-Label Zero-Shot Learning with Structured Knowledge Graphs.</strong></li>
</ol>
<p><em>Chung-Wei Lee, Wei Fang, Chih-Kuan Yeh, Yu-Chiang Frank Wang.</em> CVPR 2018. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1711.06526.pdf">paper</a></p>
<ol>
<li><strong>Dynamic Graph Generation Network: Generating Relational Knowledge from Diagrams.</strong></li>
</ol>
<p><em>Daesik Kim, Youngjoon Yoo, Jeesoo Kim, Sangkuk Lee, Nojun Kwak.</em> CVPR 2018. <a target="_blank" rel="noopener" href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Kim_Dynamic_Graph_Generation_CVPR_2018_paper.pdf">paper</a></p>
<ol>
<li><strong>Deep Reasoning with Knowledge Graph for Social Relationship Understanding.</strong></li>
</ol>
<p><em>Zhouxia Wang, Tianshui Chen, Jimmy Ren, Weihao Yu, Hui Cheng, Liang Lin.</em> IJCAI 2018. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1807.00504.pdf">paper</a></p>
<ol>
<li><strong>Constructing Narrative Event Evolutionary Graph for Script Event Prediction.</strong></li>
</ol>
<p><em>Zhongyang Li, Xiao Ding, Ting Liu.</em> IJCAI 2018. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1805.05081.pdf">paper</a></p>
<ol>
<li><strong>Modeling Semantics with Gated Graph Neural Networks for Knowledge Base Question Answering.</strong></li>
</ol>
<p><em>Daniil Sorokin, Iryna Gurevych.</em> COLING 2018. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1808.04126.pdf">paper</a></p>
<ol>
<li><strong>Convolutional networks on graphs for learning molecular fingerprints.</strong></li>
</ol>
<p><em>David Duvenaud, Dougal Maclaurin, Jorge Aguilera-Iparraguirre, Rafael G�mez-Bombarelli, Timothy Hirzel, Al�n Aspuru-Guzik, Ryan P. Adams.</em> NIPS 2015. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1509.09292.pdf">paper</a></p>
<ol>
<li><strong>Molecular Graph Convolutions: Moving Beyond Fingerprints.</strong></li>
</ol>
<p><em>Steven Kearnes, Kevin McCloskey, Marc Berndl, Vijay Pande, Patrick Riley.</em> Journal of computer-aided molecular design 2016. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1603.00856.pdf">paper</a></p>
<ol>
<li><strong>Protein Interface Prediction using Graph Convolutional Networks.</strong></li>
</ol>
<p><em>Alex Fout, Jonathon Byrd, Basir Shariat, Asa Ben-Hur.</em> NIPS 2017. <a target="_blank" rel="noopener" href="http://papers.nips.cc/paper/7231-protein-interface-prediction-using-graph-convolutional-networks.pdf">paper</a></p>
<ol>
<li><strong>Traffic Graph Convolutional Recurrent Neural Network: A Deep Learning Framework for Network-Scale Traffic Learning and Forecasting.</strong></li>
</ol>
<p><em>Zhiyong Cui, Kristian Henrickson, Ruimin Ke, Yinhai Wang.</em> 2018. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1802.07007.pdf">paper</a></p>
<ol>
<li><strong>Spatio-Temporal Graph Convolutional Networks: A Deep Learning Framework for Traffic Forecasting.</strong></li>
</ol>
<p><em>Bing Yu, Haoteng Yin, Zhanxing Zhu.</em> IJCAI 2018. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1709.04875.pdf">paper</a></p>
<ol>
<li><strong>Semi-supervised User Geolocation via Graph Convolutional Networks.</strong></li>
</ol>
<p><em>Afshin Rahimi, Trevor Cohn, Timothy Baldwin.</em> ACL 2018. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1804.08049.pdf">paper</a></p>
<ol>
<li><strong>Dynamic Graph CNN for Learning on Point Clouds.</strong></li>
</ol>
<p><em>Yue Wang, Yongbin Sun, Ziwei Liu, Sanjay E. Sarma, Michael M. Bronstein, Justin M. Solomon.</em> CVPR 2018. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1801.07829.pdf">paper</a></p>
<ol>
<li><strong>PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation.</strong></li>
</ol>
<p><em>Charles R. Qi, Hao Su, Kaichun Mo, Leonidas J. Guibas.</em> CVPR 2018. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1612.00593.pdf">paper</a></p>
<ol>
<li><strong>3D Graph Neural Networks for RGBD Semantic Segmentation.</strong></li>
</ol>
<p><em>Xiaojuan Qi, Renjie Liao, Jiaya Jia, Sanja Fidler, Raquel Urtasun.</em> CVPR 2017. <a target="_blank" rel="noopener" href="http://openaccess.thecvf.com/content_ICCV_2017/papers/Qi_3D_Graph_Neural_ICCV_2017_paper.pdf">paper</a></p>
<ol>
<li><strong>Iterative Visual Reasoning Beyond Convolutions.</strong></li>
</ol>
<p><em>Xinlei Chen, Li-Jia Li, Li Fei-Fei, Abhinav Gupta.</em> CVPR 2018. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1803.11189">paper</a></p>
<ol>
<li><strong>Dynamic Edge-Conditioned Filters in Convolutional Neural Networks on Graphs.</strong></li>
</ol>
<p><em>Martin Simonovsky, Nikos Komodakis.</em> CVPR 2017. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1704.02901">paper</a></p>
<ol>
<li><strong>Situation Recognition with Graph Neural Networks.</strong></li>
</ol>
<p><em>Ruiyu Li, Makarand Tapaswi, Renjie Liao, Jiaya Jia, Raquel Urtasun, Sanja Fidler.</em> ICCV 2017. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1708.04320">paper</a></p>
<ol>
<li><strong>Conversation Modeling on Reddit using a Graph-Structured LSTM.</strong></li>
</ol>
<p><em>Vicky Zayats, Mari Ostendorf.</em> TACL 2018. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1704.02080">paper</a></p>
<ol>
<li><strong>Graph Convolutional Networks for Text Classification.</strong></li>
</ol>
<p><em>Liang Yao, Chengsheng Mao, Yuan Luo.</em> AAAI 2019. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1809.05679.pdf">paper</a></p>
<ol>
<li><strong>Attention Is All You Need.</strong></li>
</ol>
<p><em>Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin.</em> NIPS 2017. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1706.03762">paper</a></p>
<ol>
<li><strong>Self-Attention with Relative Position Representations.</strong></li>
</ol>
<p><em>Peter Shaw, Jakob Uszkoreit, Ashish Vaswani.</em> NAACL 2018. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1803.02155">paper</a></p>
<ol>
<li><strong>Hyperbolic Attention Networks.</strong></li>
</ol>
<p><em>Caglar Gulcehre, Misha Denil, Mateusz Malinowski, Ali Razavi, Razvan Pascanu, Karl Moritz Hermann, Peter Battaglia, Victor Bapst, David Raposo, Adam Santoro, Nando de Freitas</em> 2018. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1805.09786">paper</a></p>
<ol>
<li><strong>Effective Approaches to Attention-based Neural Machine Translation.</strong></li>
</ol>
<p><em>Minh-Thang Luong, Hieu Pham, Christopher D. Manning.</em> EMNLP 2015. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1508.04025">paper</a></p>
<ol>
<li><strong>Graph Convolutional Encoders for Syntax-aware Neural Machine Translation.</strong></li>
</ol>
<p><em>Joost Bastings, Ivan Titov, Wilker Aziz, Diego Marcheggiani, Khalil Sima’an.</em> EMNLP 2017. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1704.04675">paper</a></p>
<ol>
<li><strong>NerveNet: Learning Structured Policy with Graph Neural Networks.</strong></li>
</ol>
<p><em>Tingwu Wang, Renjie Liao, Jimmy Ba, Sanja Fidler.</em> ICLR 2018. <a target="_blank" rel="noopener" href="https://openreview.net/pdf?id=S1sqHMZCb">paper</a></p>
<ol>
<li><strong>Metacontrol for Adaptive Imagination-Based Optimization.</strong></li>
</ol>
<p><em>Jessica B. Hamrick, Andrew J. Ballard, Razvan Pascanu, Oriol Vinyals, Nicolas Heess, Peter W. Battaglia.</em> ICLR 2017. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1705.02670">paper</a></p>
<ol>
<li><strong>Learning model-based planning from scratch.</strong></li>
</ol>
<p><em>Razvan Pascanu, Yujia Li, Oriol Vinyals, Nicolas Heess, Lars Buesing, Sebastien Racani�re, David Reichert, Th�ophane Weber, Daan Wierstra, Peter Battaglia.</em> 2017. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1707.06170">paper</a></p>
<ol>
<li><strong>Structured Dialogue Policy with Graph Neural Networks.</strong></li>
</ol>
<p><em>Lu Chen, Bowen Tan, Sishan Long and Kai Yu.</em> ICCL 2018. <a target="_blank" rel="noopener" href="http://www.aclweb.org/anthology/C18-1107">paper</a></p>
<ol>
<li><strong>Relational inductive bias for physical construction in humans and machines.</strong></li>
</ol>
<p><em>Jessica B. Hamrick, Kelsey R. Allen, Victor Bapst, Tina Zhu, Kevin R. McKee, Joshua B. Tenenbaum, Peter W. Battaglia.</em> CogSci 2018. <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1806.01203">paper</a></p>
<ol>
<li><strong>Relational Deep Reinforcement Learning.</strong></li>
</ol>
<p><em>Vinicius Zambaldi, David Raposo, Adam Santoro, Victor Bapst, Yujia Li, Igor Babuschkin, Karl Tuyls, David Reichert, Timothy Lillicrap, Edward Lockhart, Murray Shanahan, Victoria Langston, Razvan Pascanu, Matthew Botvinick, Oriol Vinyals, Peter Battaglia.</em> 2018. <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1806.01830">paper</a></p>
<ol>
<li><strong>Action Schema Networks: Generalised Policies with Deep Learning.</strong></li>
</ol>
<p><em>Sam Toyer, Felipe Trevizan, Sylvie Thi�baux, Lexing Xie.</em> AAAI 2018. <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1709.04271">paper</a></p>
<ol>
<li><strong>Neural Combinatorial Optimization with Reinforcement Learning.</strong></li>
</ol>
<p><em>Irwan Bello, Hieu Pham, Quoc V. Le, Mohammad Norouzi, Samy Bengio.</em> 2016. <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1611.09940">paper</a></p>
<ol>
<li><strong>A Note on Learning Algorithms for Quadratic Assignment with Graph Neural Networks.</strong></li>
</ol>
<p><em>Alex Nowak, Soledad Villar, Afonso S. Bandeira, Joan Bruna.</em> PADL 2017. <a target="_blank" rel="noopener" href="https://www.padl.ws/papers/Paper%2017.pdf">paper</a></p>
<ol>
<li><strong>Learning Combinatorial Optimization Algorithms over Graphs.</strong></li>
</ol>
<p><em>Hanjun Dai, Elias B. Khalil, Yuyu Zhang, Bistra Dilkina, Le Song.</em> NIPS 2017. <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1704.01665">paper</a></p>
<ol>
<li><strong>Attention Solves Your TSP, Approximately.</strong></li>
</ol>
<p><em>Wouter Kool, Herke van Hoof, Max Welling.</em> 2018. <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1803.08475">paper</a></p>
<ol>
<li><strong>Learning a SAT Solver from Single-Bit Supervision.</strong></li>
</ol>
<p><em>Daniel Selsam, Matthew Lamm, Benedikt B�nz, Percy Liang, Leonardo de Moura, David L. Dill.</em> 2018. <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1802.03685">paper</a></p>
<ol>
<li><strong>Learning to Represent Programs with Graphs.</strong></li>
</ol>
<p><em>Miltiadis Allamanis, Marc Brockschmidt, Mahmoud Khademi.</em> ICLR 2018. <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1711.00740">paper</a></p>
<ol>
<li><strong>Learning Graphical State Transitions.</strong></li>
</ol>
<p><em>Daniel D. Johnson.</em> ICLR 2017. <a target="_blank" rel="noopener" href="https://openreview.net/forum?id=HJ0NvFzxl">paper</a></p>
<ol>
<li><strong>Inference in Probabilistic Graphical Models by Graph Neural Networks.</strong></li>
</ol>
<p><em>KiJung Yoon, Renjie Liao, Yuwen Xiong, Lisa Zhang, Ethan Fetaya, Raquel Urtasun, Richard Zemel, Xaq Pitkow.</em> ICLR Workshop 2018. <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1803.07710">paper</a></p>
<ol>
<li><strong>Learning deep generative models of graphs.</strong></li>
</ol>
<p><em>Yujia Li, Oriol Vinyals, Chris Dyer, Razvan Pascanu, Peter Battaglia.</em> ICLR Workshop 2018. <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1803.03324">paper</a></p>
<ol>
<li><strong>MolGAN: An implicit generative model for small molecular graphs.</strong></li>
</ol>
<p><em>Nicola De Cao, Thomas Kipf.</em> 2018. <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1805.11973">paper</a></p>
<ol>
<li><strong>GraphRNN: Generating Realistic Graphs with Deep Auto-regressive Models.</strong></li>
</ol>
<p><em>Jiaxuan You, Rex Ying, Xiang Ren, William L. Hamilton, Jure Leskovec.</em> ICML 2018. <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1802.08773">paper</a></p>
<ol>
<li><strong>NetGAN: Generating Graphs via Random Walks.</strong></li>
</ol>
<p><em>Aleksandar Bojchevski, Oleksandr Shchur, Daniel Z�gner, Stephan G�nnemann.</em> ICML 2018. <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1803.00816">paper</a></p>
<ol>
<li><strong>Adversarial Attack on Graph Structured Data.</strong></li>
</ol>
<p><em>Hanjun Dai, Hui Li, Tian Tian, Xin Huang, Lin Wang, Jun Zhu, Le Song.</em> ICML 2018. <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1806.02371">paper</a></p>
<ol>
<li><strong>Graph Convolutional Neural Networks for Web-Scale Recommender Systems.</strong></li>
</ol>
<p><em>Rex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, William L. Hamilton, Jure Leskovec.</em> KDD 2018. <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1806.01973">paper</a></p>
<ol>
<li><strong>Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks.</strong></li>
</ol>
<p><em>Kai Sheng Tai, Richard Socher, Christopher D. Manning.</em> ACL 2015. <a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/P15-1150">paper</a></p>
<ol>
<li><strong>Neural Module Networks.</strong></li>
</ol>
<p><em>Jacob Andreas, Marcus Rohrbach, Trevor Darrell, Dan Klein.</em> CVPR 2016. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1511.02799.pdf">paper</a></p>
<ol>
<li><strong>Encoding Sentences with Graph Convolutional Networks for Semantic Role Labeling.</strong></li>
</ol>
<p><em>Diego Marcheggiani, Ivan Titov.</em> EMNLP 2017. <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1703.04826">paper</a></p>
<ol>
<li><strong>Graph Convolutional Networks with Argument-Aware Pooling for Event Detection.</strong></li>
</ol>
<p><em>Thien Huu Nguyen, Ralph Grishman.</em> AAAI 2018. <a target="_blank" rel="noopener" href="http://ix.cs.uoregon.edu/~thien/pubs/graphConv.pdf">paper</a></p>
<ol>
<li><strong>Geometric Matrix Completion with Recurrent Multi-Graph Neural Networks.</strong></li>
</ol>
<p><em>Federico Monti, Michael M. Bronstein, Xavier Bresson.</em> NIPS 2017. <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1704.06803">paper</a></p>
<ol>
<li><strong>Graph Convolutional Matrix Completion.</strong></li>
</ol>
<p><em>Rianne van den Berg, Thomas N. Kipf, Max Welling.</em> 2017. <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1706.02263">paper</a></p>
<ol>
<li><strong>Hybrid Approach of Relation Network and Localized Graph Convolutional Filtering for Breast Cancer Subtype Classification.</strong></li>
</ol>
<p><em>Sungmin Rhee, Seokjun Seo, Sun Kim.</em> IJCAI 2018. <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1711.05859">paper</a></p>
<ol>
<li><strong>Modeling polypharmacy side effects with graph convolutional networks.</strong></li>
</ol>
<p><em>Marinka Zitnik, Monica Agrawal, Jure Leskovec.</em> ISMB 2018. <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1802.00543">paper</a></p>
<ol>
<li><strong>DeepInf: Modeling influence locality in large social networks.</strong></li>
</ol>
<p><em>Jiezhong Qiu, Jian Tang, Hao Ma, Yuxiao Dong, Kuansan Wang, Jie Tang.</em> KDD 2018. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1807.05560.pdf">paper</a></p>
<ol>
<li><strong>Exploiting Semantics in Neural Machine Translation with Graph Convolutional Networks.</strong></li>
</ol>
<p><em>Diego Marcheggiani, Joost Bastings, Ivan Titov.</em> NAACL 2018. <a target="_blank" rel="noopener" href="http://www.aclweb.org/anthology/N18-2078">paper</a></p>
<ol>
<li><strong>Exploring Graph-structured Passage Representation for Multi-hop Reading Comprehension with Graph Neural Networks.</strong></li>
</ol>
<p><em>Linfeng Song, Zhiguo Wang, Mo Yu, Yue Zhang, Radu Florian, Daniel Gildea.</em> 2018. <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1809.02040">paper</a></p>
<ol>
<li><strong>Graph Convolution over Pruned Dependency Trees Improves Relation Extraction.</strong></li>
</ol>
<p><em>Yuhao Zhang, Peng Qi, Christopher D. Manning.</em> EMNLP 2018. <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1809.10185">paper</a></p>
<ol>
<li><strong>N-ary relation extraction using graph state LSTM.</strong></li>
</ol>
<p><em>Linfeng Song, Yue Zhang, Zhiguo Wang, Daniel Gildea.</em> EMNLP 18. <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1808.09101">paper</a></p>
<ol>
<li><strong>A Graph-to-Sequence Model for AMR-to-Text Generation.</strong></li>
</ol>
<p><em>Linfeng Song, Yue Zhang, Zhiguo Wang, Daniel Gildea.</em> ACL 2018. <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1805.02473">paper</a></p>
<ol>
<li><strong>Cross-Sentence N-ary Relation Extraction with Graph LSTMs.</strong></li>
</ol>
<p><em>Nanyun Peng, Hoifung Poon, Chris Quirk, Kristina Toutanova, Wen-tau Yih.</em> TACL. <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1708.03743">paper</a></p>
<ol>
<li><strong>Sentence-State LSTM for Text Representation.</strong></li>
</ol>
<p><em>Yue Zhang, Qi Liu, Linfeng Song.</em>  ACL 2018. <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1805.02474">paper</a></p>
<ol>
<li><strong>End-to-End Relation Extraction using LSTMs on Sequences and Tree Structures.</strong></li>
</ol>
<p><em>Makoto Miwa, Mohit Bansal.</em> ACL 2016. <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1601.00770">paper</a></p>
<ol>
<li><strong>Learning Human-Object Interactions by Graph Parsing Neural Networks.</strong></li>
</ol>
<p><em>Siyuan Qi, Wenguan Wang, Baoxiong Jia, Jianbing Shen, Song-Chun Zhu.</em> ECCV 2018. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1808.07962.pdf">paper</a></p>
<ol>
<li><strong>Multiple Events Extraction via Attention-based Graph Information Aggregation.</strong></li>
</ol>
<p><em>Xiao Liu, Zhunchen Luo, Heyan Huang.</em> EMNLP 2018. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1809.09078.pdf">paper</a></p>
<ol>
<li><strong>Cross-lingual Knowledge Graph Alignment via Graph Convolutional Networks.</strong></li>
</ol>
<p><em>Zhichun Wang, Qingsong Lv, Xiaohan Lan, Yu Zhang.</em> EMNLP 2018. <a target="_blank" rel="noopener" href="http://www.aclweb.org/anthology/D18-1032">paper</a></p>
<ol>
<li><strong>Graph Convolution over Pruned Dependency Trees Improves Relation Extraction.</strong></li>
</ol>
<p><em>Yuhao Zhang, Peng Qi, Christopher D. Manning.</em> EMNLP 2018. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1809.10185">paper</a></p>
<ol>
<li><strong>Recurrent Relational Networks.</strong></li>
</ol>
<p><em>Rasmus Palm, Ulrich Paquet, Ole Winther.</em> NeurIPS 2018. <a target="_blank" rel="noopener" href="http://papers.nips.cc/paper/7597-recurrent-relational-networks.pdf">paper</a></p>
<ol>
<li><strong>Graph Convolutional Policy Network for Goal-Directed Molecular Graph Generation.</strong></li>
</ol>
<p><em>Jiaxuan You, Bowen Liu, Rex Ying, Vijay Pande, Jure Leskovec.</em> NeurIPS 2018. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1806.02473">paper</a></p>
<ol>
<li><strong>Learning Conditioned Graph Structures for Interpretable Visual Question Answering.</strong></li>
</ol>
<p><em>Will Norcliffe-Brown, Efstathios Vafeias, Sarah Parisot.</em> NeurIPS 2018. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1806.07243">paper</a></p>
<ol>
<li><strong>Combinatorial Optimization with Graph Convolutional Networks and Guided Tree Search.</strong></li>
</ol>
<p><em>Zhuwen Li, Qifeng Chen, Vladlen Koltun.</em> NeurIPS 2018. <a target="_blank" rel="noopener" href="http://papers.nips.cc/paper/7335-combinatorial-optimization-with-graph-convolutional-networks-and-guided-tree-search.pdf">paper</a></p>
<ol>
<li><strong>Symbolic Graph Reasoning Meets Convolutions.</strong></li>
</ol>
<p><em>Xiaodan Liang, Zhiting Hu, Hao Zhang, Liang Lin, Eric P. Xing.</em> NeurIPS 2018. <a target="_blank" rel="noopener" href="http://papers.nips.cc/paper/7456-symbolic-graph-reasoning-meets-convolutions.pdf">paper</a></p>
<ol>
<li><strong>Out of the Box: Reasoning with Graph Convolution Nets for Factual Visual Question Answering.</strong></li>
</ol>
<p><em>Medhini Narasimhan, Svetlana Lazebnik, Alexander Schwing.</em> NeurIPS 2018. <a target="_blank" rel="noopener" href="http://papers.nips.cc/paper/7531-out-of-the-box-reasoning-with-graph-convolution-nets-for-factual-visual-question-answering.pdf">paper</a></p>
<ol>
<li><strong>Constrained Generation of Semantically Valid Graphs via Regularizing Variational Autoencoders.</strong></li>
</ol>
<p><em>Tengfei Ma, Jie Chen, Cao Xiao.</em> NeurIPS 2018. <a target="_blank" rel="noopener" href="https://papers.nips.cc/paper/7942-constrained-generation-of-semantically-valid-graphs-via-regularizing-variational-autoencoders.pdf">paper</a></p>
<ol>
<li><strong>Structural-RNN: Deep Learning on Spatio-Temporal Graphs.</strong></li>
</ol>
<p><em>Ashesh Jain, Amir R. Zamir, Silvio Savarese, Ashutosh Saxena.</em> CVPR 2016. <a target="_blank" rel="noopener" href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Jain_Structural-RNN_Deep_Learning_CVPR_2016_paper.pdf">paper</a></p>
<ol>
<li><strong>Relation Networks for Object Detection.</strong></li>
</ol>
<p><em>Han Hu, Jiayuan Gu, Zheng Zhang, Jifeng Dai, Yichen Wei.</em> CVPR 2018. <a target="_blank" rel="noopener" href="http://openaccess.thecvf.com/content_cvpr_2018/papers_backup/Hu_Relation_Networks_for_CVPR_2018_paper.pdf">paper</a></p>
<ol>
<li><strong>Learning Region features for Object Detection.</strong></li>
</ol>
<p><em>Jiayuan Gu, Han Hu, Liwei Wang, Yichen Wei, Jifeng Dai.</em> ECCV 2018. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1803.07066">paper</a></p>
<ol>
<li><strong>Deep Graph Infomax.</strong></li>
</ol>
<p><em>Petar Veli?kovi?, William Fedus, William L. Hamilton, Pietro Li�, Yoshua Bengio, R Devon Hjelm.</em> ICLR 2019. <a target="_blank" rel="noopener" href="https://openreview.net/pdf?id=rklz9iAcKQ">paper</a></p>
<ol>
<li><strong>Combining Neural Networks with Personalized PageRank for Classification on Graphs.</strong></li>
</ol>
<p><em>Johannes Klicpera, Aleksandar Bojchevski, Stephan G�nnemann.</em> ICLR 2019. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1810.05997.pdf">paper</a></p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/GNN/" rel="tag">GNN</a></li></ul>

    </footer>
  </div>

    
 
   
</article>

    
    <article
  id="post-工程数学笔记"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2019/01/18/%E5%B7%A5%E7%A8%8B%E6%95%B0%E5%AD%A6%E7%AC%94%E8%AE%B0/"
    >工程数学笔记</a> 
</h2>
 

    </header>
     
    <div class="article-meta">
      <a href="/2019/01/18/%E5%B7%A5%E7%A8%8B%E6%95%B0%E5%AD%A6%E7%AC%94%E8%AE%B0/" class="article-date">
  <time datetime="2019-01-18T03:22:25.000Z" itemprop="datePublished">2019-01-18</time>
</a>    
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h1 id="数值计算笔记"><a href="#数值计算笔记" class="headerlink" title="数值计算笔记"></a>数值计算笔记</h1><p><img src="https://i.loli.net/2019/01/18/5c41bbb523a79.jpg" alt="微信图片_201901181119471.jpg"></p>
<p><img src="https://i.loli.net/2019/01/18/5c41bbb386ec9.jpg" alt="微信图片_201901181119461.jpg"></p>
<p><img src="https://i.loli.net/2019/01/18/5c41bbb34958f.jpg" alt="微信图片_201901181119473.jpg"></p>
<p><img src="https://i.loli.net/2019/01/18/5c41bbb25a089.jpg" alt="微信图片_201901181119472.jpg"></p>
<p><img src="https://i.loli.net/2019/01/18/5c41bbb4a94d4.jpg" alt="微信图片_20190118111947.jpg"></p>
<p><img src="https://i.loli.net/2019/01/18/5c41bbb4c7d16.jpg" alt="微信图片_20190118111946.jpg"></p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%95%B0%E5%AD%A6/" rel="tag">数学</a></li></ul>

    </footer>
  </div>

    
 
   
</article>

    
    <article
  id="post-算法分析与设计"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2019/01/01/%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90%E4%B8%8E%E8%AE%BE%E8%AE%A1/"
    >算法分析与设计</a> 
</h2>
 

    </header>
     
    <div class="article-meta">
      <a href="/2019/01/01/%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90%E4%B8%8E%E8%AE%BE%E8%AE%A1/" class="article-date">
  <time datetime="2019-01-01T02:17:01.000Z" itemprop="datePublished">2019-01-01</time>
</a>    
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h1 id="第一章"><a href="#第一章" class="headerlink" title="第一章"></a>第一章</h1><ol>
<li><strong>最大公约数算法</strong>：<ul>
<li>gcd(m, n) = gcd(n, m mod n)</li>
<li>结束条件是 m%n = 0</li>
</ul>
</li>
</ol>
<h1 id="第二章"><a href="#第二章" class="headerlink" title="第二章"></a>第二章</h1><ol>
<li><strong>算法时间效率度量</strong> —— 基本操作的执行次数。</li>
<li><strong>渐进符号</strong>（可以按照复杂程度记忆，最简单的为上界，最复杂的为下界）<br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyqvq0dr35j30zv0matd7.jpg" alt="1"></li>
<li>斐波那契数列<br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyqw4dwrf0j30kh0f5jss.jpg" alt="2"><ul>
<li>参数 α，β 可以通过 F(1)、F(2)联立方程组解出来</li>
</ul>
</li>
</ol>
<h1 id="第三章"><a href="#第三章" class="headerlink" title="第三章"></a>第三章</h1><ol>
<li><p><strong>选择排序</strong><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyqwaev3q0j312a0rjtfl.jpg" alt="3"></p>
</li>
<li><p><strong>冒泡排序</strong><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyqwdhyujzj313z0r410o.jpg" alt="4"></p>
</li>
<li><p><strong>幻方</strong><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyqwoxzdqpj310j0psq73.jpg" alt="5"><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyqwpl5gufj313c0pxjxd.jpg" alt="6"></p>
</li>
</ol>
<h1 id="第四章"><a href="#第四章" class="headerlink" title="第四章"></a>第四章</h1><ol>
<li><p><strong>分治法</strong><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyqxjm0uujj31040ts10h.jpg" alt="7"></p>
</li>
<li><p><strong>合并排序</strong><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyqy3tlh99j30z30ondip.jpg" alt="8"><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyqy2s4152j30yp0r4n1t.jpg" alt="9"><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyr1ieyoxdj312s0qlq5k.jpg" alt="10"><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyr1jbpuyjj31050rqtcj.jpg" alt="11"><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyr1kum4eej311d0jeju8.jpg" alt="12"></p>
</li>
<li><p><strong>快速排序</strong><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyr1qw61urj30us0os44s.jpg" alt="13"><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyr1s0tmt1j30uq0mvae2.jpg" alt="14"><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyr1snlhkjj30v60n9tga.jpg" alt="15"><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyr1tlh17cj30w70nwgra.jpg" alt="16"><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyr1ucolzrj30up0or42w.jpg" alt="17"></p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"><span class="keyword">int</span> a[<span class="number">5</span>], n;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">quickSort</span><span class="params">(<span class="keyword">int</span> left, <span class="keyword">int</span> right)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (left &gt;= right)</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    <span class="keyword">int</span> i, j, t, temp;</span><br><span class="line">    i = left;</span><br><span class="line">    j = right;</span><br><span class="line">    temp = a[left];</span><br><span class="line">    <span class="keyword">while</span> (<span class="literal">true</span>)&#123;</span><br><span class="line">        <span class="keyword">while</span> (a[j] &gt;= temp &amp;&amp; i &lt; j)&#123;</span><br><span class="line">            j--;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">while</span> (a[i] &lt;= temp &amp;&amp; i &lt; j)&#123;</span><br><span class="line">            i++;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (i &lt; j)&#123;</span><br><span class="line">            t = a[i];</span><br><span class="line">            a[i] = a[j];</span><br><span class="line">            a[j] = t;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    a[left] = a[j];</span><br><span class="line">    a[j] = temp;</span><br><span class="line">    quickSort(left, i - <span class="number">1</span>);</span><br><span class="line">    quickSort(i + <span class="number">1</span>, right);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= <span class="number">5</span>; i++)&#123;</span><br><span class="line">        <span class="built_in">cin</span> &gt;&gt; a[i];</span><br><span class="line">    &#125;</span><br><span class="line">    quickSort(<span class="number">1</span>, n);</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= <span class="number">5</span>; i++)&#123;</span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; a[i] &lt;&lt; <span class="string">&quot; &quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>大整数乘法</strong><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyr51lds72j30se0j0juu.jpg" alt="18"><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyr52dd56wj30tv0jt42l.jpg" alt="19"></p>
</li>
<li><p><strong>Strassen 矩阵乘法</strong><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyr5lam69mj30uc0lt0vr.jpg" alt="20"><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyr5m107vij30th0krjul.jpg" alt="21"></p>
</li>
</ol>
<h1 id="第五章"><a href="#第五章" class="headerlink" title="第五章"></a>第五章</h1><ol>
<li><strong>减治算法</strong><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyr6ph0mzgj31170rrguo.jpg" alt="22"><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyr6qh01sej30y90pfjx6.jpg" alt="23"><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyr6rcg9jtj31090pun41.jpg" alt="24"></li>
</ol>
<h1 id="第六章"><a href="#第六章" class="headerlink" title="第六章"></a>第六章</h1><ol>
<li><p><strong>平衡二叉树</strong></p>
<blockquote>
<p>这里的 LR 旋转是相对的概念, 意思是先变成左子树再向右旋转。</p>
</blockquote>
<p><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyre3ydw8cj30u0140tj8.jpg" alt="25"></p>
</li>
<li><p><strong>2-3 树</strong></p>
<blockquote>
<p>2-3 树是一种特殊的高度平衡树，允许结点最多包含两个关键字。<br>❑ 2-node:包含一个关键字，两个子节点<br>❑ 3-node:包含两个关键字，三个子节点</p>
</blockquote>
<p><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyreus7u67j30qn0hdakf.jpg" alt="26"></p>
</li>
<li><p><strong>Horner 法则</strong><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyrf3av83ej30z00jldiw.jpg" alt="27"><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyrfsexfvhj310u0mtk54.jpg" alt="28"><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyrf59pwg5j310z0rgdkh.jpg" alt="29"><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyrft1qi8yj30mq06gdjp.jpg" alt="30"></p>
</li>
</ol>
<h1 id="第七章"><a href="#第七章" class="headerlink" title="第七章"></a>第七章</h1><ol>
<li><p><strong>计数排序</strong><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fysbvkrghoj312s0r6n1t.jpg" alt="31"><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fysbwb7q37j30kw0oj76t.jpg" alt="32"></p>
</li>
<li><p><strong>分布计数排序</strong><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fysd6sdp2uj30ya0myq6k.jpg" alt="33"><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fysd9p1jdgj30y70nrae5.jpg" alt="34"></p>
<p>实现代码：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"><span class="keyword">int</span> a[<span class="number">10</span>], l, u, D[<span class="number">10</span>], S[<span class="number">10</span>];</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">DistributeSort</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt;= u - l; i++)&#123;</span><br><span class="line">        D[i] = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++)&#123;</span><br><span class="line">        D[a[i] - l]++;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= u - l; i++)&#123;</span><br><span class="line">        D[i] += D[i - <span class="number">1</span>];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">9</span>; i &gt;= <span class="number">0</span>; i--)&#123;</span><br><span class="line">        <span class="keyword">int</span> j = a[i] - l;</span><br><span class="line">        S[D[j] - <span class="number">1</span>] = a[i];</span><br><span class="line">        D[j] -= <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++)&#123;</span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; S[i] &lt;&lt; <span class="string">&quot; &quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    l = <span class="number">1</span>, u = <span class="number">3</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++)&#123;</span><br><span class="line">        <span class="built_in">cin</span> &gt;&gt; a[i]; <span class="comment">// 1 2 3 1 2 3 1 2 3 1</span></span><br><span class="line">    &#125;</span><br><span class="line">    DistributeSort();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ol>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%AE%97%E6%B3%95/" rel="tag">算法</a></li></ul>

    </footer>
  </div>

    
 
   
</article>

    
    <article
  id="post-软件过程重点知识梳理"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2018/12/28/%E8%BD%AF%E4%BB%B6%E8%BF%87%E7%A8%8B%E9%87%8D%E7%82%B9%E7%9F%A5%E8%AF%86%E6%A2%B3%E7%90%86/"
    >软件过程重点知识梳理</a> 
</h2>
 

    </header>
     
    <div class="article-meta">
      <a href="/2018/12/28/%E8%BD%AF%E4%BB%B6%E8%BF%87%E7%A8%8B%E9%87%8D%E7%82%B9%E7%9F%A5%E8%AF%86%E6%A2%B3%E7%90%86/" class="article-date">
  <time datetime="2018-12-28T00:52:02.000Z" itemprop="datePublished">2018-12-28</time>
</a>    
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h1 id="高级软件开发过程重点知识"><a href="#高级软件开发过程重点知识" class="headerlink" title="高级软件开发过程重点知识"></a>高级软件开发过程重点知识</h1><h2 id="1-绪论"><a href="#1-绪论" class="headerlink" title="1. 绪论"></a>1. 绪论</h2><ul>
<li><strong>软件过程定义</strong>：从软件需求定义开始到软件废弃为止，跨越整个生命周期内的系统开发、运行、维护等全部活动及其相关项的总和。</li>
<li><strong>软件发展三阶段</strong>：程序设计、软件工程、软件过程</li>
<li><strong>软件过程能力评估标准和改进方案</strong>：CMM, ISO, 6 西格玛</li>
<li><strong>生命周期模型</strong>：瀑布模型、原型模型、螺旋模型、喷泉模型</li>
<li><strong>软件过程与软件工程的关系</strong>：包含关系</li>
<li><strong>软件过程模式的意义</strong>：<ul>
<li>四要素</li>
<li>快速把握软件过程的本质、原则、规范、特点、策略等</li>
<li>分析优缺点</li>
</ul>
</li>
</ul>
<h2 id="2-Rational-统一开发过程"><a href="#2-Rational-统一开发过程" class="headerlink" title="2. Rational 统一开发过程"></a>2. Rational 统一开发过程</h2><ul>
<li><p><strong>三大特点</strong>：</p>
<ul>
<li>用力驱动</li>
<li>以架构为中心</li>
<li>迭代与增量</li>
</ul>
</li>
<li><p>工作流程不仅仅指活动，还表明了角色、活动、工件是一个逻辑整体。</p>
</li>
<li><p><strong>RUP 二维结构图</strong><br><img src="https://pic002.cnblogs.com/images/2012/444673/2012091916323986.png" alt="RUP"></p>
<ul>
<li>静态特征：纵轴的内容组织</li>
<li>动态特征：横轴的时间组织</li>
<li>RUP 独特的地方<ul>
<li>并行化</li>
<li>阶段内部迭代</li>
<li>工作流中多出的几个新的概念</li>
<li>明确的里程碑</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>九大核心工作流程</strong></p>
<ul>
<li>核心过程<ul>
<li>业务建模</li>
<li>需求</li>
<li>分析设计</li>
<li>实施</li>
<li>测试</li>
<li>部署</li>
</ul>
</li>
<li>核心支持<ul>
<li>配置、变更管理</li>
<li>项目管理</li>
<li>环境</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>工件</strong>：模型、元素、文档、源代码、可执行文件、工具等。</p>
</li>
<li><p><strong>四阶段</strong>：</p>
<ul>
<li>先启（目标）</li>
<li>精化（架构）</li>
<li>构建（初始化、产品是否稳定、迭代次数最多）</li>
<li>产品化（产品发布、用户是否满意）</li>
</ul>
</li>
<li><p><strong>五大角色</strong></p>
<ul>
<li>分析员</li>
<li>开发人员</li>
<li>测试员</li>
<li>经理</li>
<li>其他角色</li>
</ul>
</li>
<li><p><strong>角色的意义</strong>（两步走）：</p>
<ul>
<li>迭代计划时，确定角色</li>
<li>人员计划时，考虑个体的技能特长，分配角色</li>
</ul>
</li>
<li><p><strong>角色方面的缺陷</strong>：未给出角色的组织管理方式、角色之间的地位和交互关系。</p>
</li>
<li><p><strong>用例的缺点及其解决方法</strong>：非功能性需求表现不足，可用补充说明文档解决。</p>
</li>
<li><p><strong>架构视图</strong>：</p>
<ul>
<li>用例模型视图</li>
<li>分析模型视图</li>
<li>设计模型视图</li>
<li>实施模型视图</li>
<li>实现模型视图</li>
<li>补充【<strong>架构必须留有复用和进化空间</strong>】</li>
</ul>
</li>
<li><p><strong>RUP 的优点</strong></p>
<ul>
<li>二维迭代，有利于降低风险，适应新需求</li>
<li>可配置，具有通用性</li>
<li>包含四要素的详尽的阐述</li>
<li>有现成的使用工具，具有操作性、可实现性</li>
</ul>
</li>
<li><p><strong>RUP 的缺点</strong></p>
<ul>
<li>四要素关系及其优先级未给出</li>
<li>生命周期各元素的关旭和优先级未给出</li>
<li>人员之间的优先级和协作方式未给出</li>
<li>产品和方法之间的优先级未给出</li>
</ul>
</li>
</ul>
<h2 id="3-敏捷开发过程"><a href="#3-敏捷开发过程" class="headerlink" title="3. 敏捷开发过程"></a>3. 敏捷开发过程</h2><ul>
<li><p><strong>4 条基本价值观</strong></p>
<ul>
<li>个体和交互胜过过程和工具（人员、生命周期、方法）</li>
<li>可以工作的软件胜过面面俱到的文档（产品）</li>
<li>客户合作胜过合同谈判（人员）</li>
<li>响应变化胜过遵循计划（方法）</li>
</ul>
</li>
<li><p><strong>12 条基本原则</strong><br>1、我们的最高目标是，通过尽早和持续地交付有价值的软件来满足客户。<br>2、欢迎对需求提出变更——即使是在项目开发后期。要善于利用需求变更，帮助客户获得竞争优势。<br>3、要不断交付可用的软件，周期从几周到几个月不等，且越短越好。<br>4、项目过程中，业务人员与开发人员必须在一起工作。<br>5、要善于激励项目人员，给他们以所需要的环境和支持，并相信他们能够完成任务。<br>6、无论是团队内还是团队间，最有效的沟通方法是面对面的交谈。<br>7、可用的软件是衡量进度的主要指标。<br>8、敏捷过程提倡可持续的开发。项目方、开发人员和用户应该能够保持恒久稳定的进展速度。<br>9、对技术的精益求精以及对设计的不断完善将提升敏捷性。<br>10、要做到简洁，即尽最大可能减少不必要的工作。这是一门艺术。<br>11、最佳的架构、需求和设计出自于自组织的团队。<br>12、团队要定期反省如何能够做到更有效，并相应地调整团队的行为。</p>
<ul>
<li>分类：<ul>
<li>生命周期(1,3,7,8)</li>
<li>人员(4,5,6,11,12)</li>
<li>产品(无)</li>
<li>方法(2,9,10)</li>
</ul>
</li>
</ul>
</li>
<li><p>计划游戏（制定细致度逐渐降低的计划）</p>
</li>
<li><p>持续集成</p>
</li>
<li><p>结对编程</p>
</li>
<li><p>隐喻（全局视图、未来影像）</p>
</li>
</ul>
<h2 id="4-微软开发过程"><a href="#4-微软开发过程" class="headerlink" title="4. 微软开发过程"></a>4. 微软开发过程</h2><ul>
<li><p><strong>术语</strong></p>
<ul>
<li>项目前景与项目范围</li>
<li>功能说明书</li>
<li>程序经理</li>
</ul>
</li>
<li><p><strong>过程原则</strong></p>
<ul>
<li>制定计划时兼顾未来的不确定因素</li>
<li>通过有效的风险管理减少不确定因素的影响</li>
<li>经常生成过度版本，并进行快速测试来提高产品的稳定性和可预测性</li>
<li>快速循环、递进的开发过程</li>
<li>从产品特性和成本能控制出发创造性的工作</li>
<li>创建确定的进度表</li>
<li>使用小型项目组并发的完成工作，并设置多个同步点</li>
<li>将大型项目分解为多个可管理的单元，以便快速的发布产品</li>
<li>用产品的前景目标和概要说明指导项目开发工作——先基线化，后冻结</li>
<li>避免产品走形</li>
<li>使用原型验证概念，进行开发前的测试</li>
<li>零缺陷观念</li>
<li>非责难式的里程碑评审会</li>
</ul>
</li>
<li><p><strong>组队原则</strong></p>
<ul>
<li>小型的、多元化的项目组</li>
<li>角色依赖、职责共享</li>
<li>专深的技术水平和业务技能</li>
<li>以产品发布为中心</li>
<li>明确的目标</li>
<li>客户的主动参与</li>
<li>分享产品的前景</li>
<li>所有人都参与设计</li>
<li>认真从过去的项目中吸取经验</li>
<li>共同管理、共同决策</li>
<li>项目组成员在同一地点办公</li>
<li>大型项目组也像小型项目组那样运作</li>
</ul>
</li>
<li><p><strong>微软过程生命周期</strong></p>
<blockquote>
<p>相当于 RUP 的生命周期的精简版，但是微软生命周期的特色在于其每个阶段设置的缓冲时间</p>
</blockquote>
<ul>
<li>构想（先启）</li>
<li>计划（精化）</li>
<li>开发（精化）</li>
<li>稳定（构建）</li>
<li>发布（产品化）</li>
</ul>
</li>
<li><p><strong>微软角色划分</strong></p>
<blockquote>
<p>以前的项目经理被拆分为产品经理和程序经理，因为这项目经理往往身兼两个角色，而这两个角色之间存在着矛盾。</p>
</blockquote>
<ul>
<li>产品经理</li>
<li>程序经理</li>
<li>开发工程师</li>
<li>测试工程师</li>
<li>用户体验人员</li>
<li>发布管理人员</li>
</ul>
</li>
<li><p><strong>角色间的关系</strong></p>
<ul>
<li>对等</li>
<li>相互协作的方式是交流和沟通</li>
</ul>
<p><img src="https://ws1.sinaimg.cn/large/006wCagogy1fymjksrsvlj30k40jbatu.jpg" alt="微软项目结构"></p>
</li>
<li><p><strong>角色合并原则</strong></p>
<ul>
<li>开发人员不能兼任其他角色</li>
<li>不能试图合并两个有明显利益冲突或制约关系的职能角色</li>
</ul>
<p><img src="https://ws1.sinaimg.cn/large/006wCagogy1fymjbpk5g0j30vj0eynmf.jpg" alt="微软组对合并原则"></p>
</li>
<li><p><strong>角色合并结论</strong></p>
<ul>
<li>最小的项目组需要 3 个成员：产品经理、程序经理、开发工程师</li>
</ul>
</li>
<li><p><strong>微软均衡三角形</strong></p>
<blockquote>
<p>结论：四要素之间相互制约，任何一条边的改变都会对剩余的边造成影响。</p>
</blockquote>
<p><img src="https://ws1.sinaimg.cn/large/006wCagogy1fymj353schj30bd0a10w8.jpg" alt="均衡三角形"></p>
</li>
<li><p><strong>微软项目均衡矩阵</strong><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fymjf48wkyj30vj0m17wh.jpg" alt="项目均衡矩阵"></p>
<ul>
<li>执行方法</li>
</ul>
<p><img src="https://ws1.sinaimg.cn/large/006wCagogy1fymjifl64rj30xz0d14ee.jpg" alt="执行"></p>
</li>
<li><p><strong>RUP/AP/微软过程的关系</strong></p>
<blockquote>
<p>三者相互交叉、相互重叠，又相互区别互不包含</p>
</blockquote>
<p><img src="https://ws1.sinaimg.cn/large/006wCagogy1fymjjm74dxj30p00dlara.jpg" alt="三者之间的关系"></p>
</li>
<li><p><strong>微软每日编译生成机制</strong></p>
</li>
</ul>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91%E8%BF%87%E7%A8%8B/" rel="tag">软件开发过程</a></li></ul>

    </footer>
  </div>

    
 
   
</article>

    
    <article
  id="post-湖南大学工程数学试题"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2018/12/24/%E6%B9%96%E5%8D%97%E5%A4%A7%E5%AD%A6%E5%B7%A5%E7%A8%8B%E6%95%B0%E5%AD%A6%E8%AF%95%E9%A2%98/"
    >湖南大学工程数学试题</a> 
</h2>
 

    </header>
     
    <div class="article-meta">
      <a href="/2018/12/24/%E6%B9%96%E5%8D%97%E5%A4%A7%E5%AD%A6%E5%B7%A5%E7%A8%8B%E6%95%B0%E5%AD%A6%E8%AF%95%E9%A2%98/" class="article-date">
  <time datetime="2018-12-24T01:59:02.000Z" itemprop="datePublished">2018-12-24</time>
</a>    
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h1 id="1-第一套"><a href="#1-第一套" class="headerlink" title="1. 第一套"></a>1. 第一套</h1><p><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyhlgl7pkoj30qe0eu7c3.jpg" alt="1"><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyhlj49ddsj30yb0et7c9.jpg" alt="2"><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyhlk70mrpj30zj0hm7gh.jpg" alt="3"><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyhllfkzglj313308xjxc.jpg" alt="4"></p>
<h1 id="2-第二套"><a href="#2-第二套" class="headerlink" title="2. 第二套"></a>2. 第二套</h1><p><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyhlmwrofrj30kf0k6gsu.jpg" alt="1"><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyhlnq6kqlj30g30kijwv.jpg" alt="2"></p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E8%AF%95%E5%8D%B7/" rel="tag">试卷</a></li></ul>

    </footer>
  </div>

    
 
   
</article>

    
    <article
  id="post-最优二叉查找树"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2018/12/23/%E6%9C%80%E4%BC%98%E4%BA%8C%E5%8F%89%E6%9F%A5%E6%89%BE%E6%A0%91/"
    >最优二叉查找树</a> 
</h2>
 

    </header>
     
    <div class="article-meta">
      <a href="/2018/12/23/%E6%9C%80%E4%BC%98%E4%BA%8C%E5%8F%89%E6%9F%A5%E6%89%BE%E6%A0%91/" class="article-date">
  <time datetime="2018-12-23T09:07:22.000Z" itemprop="datePublished">2018-12-23</time>
</a>    
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h1 id="最优二叉查找树（动态规划）"><a href="#最优二叉查找树（动态规划）" class="headerlink" title="最优二叉查找树（动态规划）"></a>最优二叉查找树（动态规划）</h1><p><strong><em>参考文章</em></strong></p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/xiajun07061225/article/details/8088784">https://blog.csdn.net/xiajun07061225/article/details/8088784</a></p>
</blockquote>
<h2 id="1-算法简介"><a href="#1-算法简介" class="headerlink" title="1.算法简介"></a>1.算法简介</h2><p><img src="https://ws1.sinaimg.cn/large/006wCagogy1fygsozze4hj30zn0mm45d.jpg" alt="1"></p>
<h2 id="2-算法分析"><a href="#2-算法分析" class="headerlink" title="2.算法分析"></a>2.算法分析</h2><p><img src="https://ws1.sinaimg.cn/large/006wCagogy1fygspvi2g7j31390ovgxn.jpg" alt="2"></p>
<h2 id="3-算法举例"><a href="#3-算法举例" class="headerlink" title="3.算法举例"></a>3.算法举例</h2><p><img src="https://ws1.sinaimg.cn/large/006wCagogy1fygsrny2bnj313y0mw7e3.jpg" alt="3"></p>
<h2 id="4-算法伪代码"><a href="#4-算法伪代码" class="headerlink" title="4.算法伪代码"></a>4.算法伪代码</h2><p><img src="https://ws1.sinaimg.cn/large/006wCagogy1fygsshdaajj31320ob7a5.jpg" alt="4"></p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%AE%97%E6%B3%95/" rel="tag">算法</a></li></ul>

    </footer>
  </div>

    
 
   
</article>

    
    <article
  id="post-模式匹配算法"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2018/12/23/%E6%A8%A1%E5%BC%8F%E5%8C%B9%E9%85%8D%E7%AE%97%E6%B3%95/"
    >模式匹配算法</a> 
</h2>
 

    </header>
     
    <div class="article-meta">
      <a href="/2018/12/23/%E6%A8%A1%E5%BC%8F%E5%8C%B9%E9%85%8D%E7%AE%97%E6%B3%95/" class="article-date">
  <time datetime="2018-12-23T02:30:32.000Z" itemprop="datePublished">2018-12-23</time>
</a>    
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h1 id="Horspool-算法"><a href="#Horspool-算法" class="headerlink" title="Horspool 算法"></a>Horspool 算法</h1><p><strong><em>参考文章</em></strong></p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/en-heng/p/5095542.html">https://www.cnblogs.com/en-heng/p/5095542.html</a> <a target="_blank" rel="noopener" href="https://blog.csdn.net/appleprince88/article/details/11881323">https://blog.csdn.net/appleprince88/article/details/11881323</a></p>
</blockquote>
<h2 id="1-移动距离"><a href="#1-移动距离" class="headerlink" title="1.移动距离"></a>1.移动距离</h2><p><img src="https://ws1.sinaimg.cn/large/006wCagogy1fygh4xycbzj311q0n6afk.jpg" alt="1"></p>
<h2 id="2-算法步骤"><a href="#2-算法步骤" class="headerlink" title="2.算法步骤"></a>2.算法步骤</h2><p><img src="https://ws1.sinaimg.cn/large/006wCagogy1fygh5xofr6j30zb0hqdm5.jpg" alt="2"></p>
<h2 id="3-算法伪代码"><a href="#3-算法伪代码" class="headerlink" title="3.算法伪代码"></a>3.算法伪代码</h2><p><img src="https://ws1.sinaimg.cn/large/006wCagogy1fygh8z9ja0j310u0j249t.jpg" alt="3"></p>
<h1 id="Boyer-Moore-算法"><a href="#Boyer-Moore-算法" class="headerlink" title="Boyer-Moore 算法"></a>Boyer-Moore 算法</h1><h2 id="1-算法流程图"><a href="#1-算法流程图" class="headerlink" title="1. 算法流程图"></a>1. 算法流程图</h2><p><img src="https://ws1.sinaimg.cn/large/006wCagogy1fygixqld6hj30f30k30u9.jpg" alt="4"></p>
<h2 id="2-算法步骤-1"><a href="#2-算法步骤-1" class="headerlink" title="2. 算法步骤"></a>2. 算法步骤</h2><p><img src="https://ws1.sinaimg.cn/large/006wCagogy1fygiy99eftj30si0i9k4b.jpg" alt="5"></p>
<h2 id="3-算法举例"><a href="#3-算法举例" class="headerlink" title="3. 算法举例"></a>3. 算法举例</h2><p><strong>解析</strong>：</p>
<blockquote>
<ul>
<li>k=2 时，后缀为 AB，此时模式串中找不到另一个 AB 串，而模式串第一个字符 B 又和 AB 串的最后一个字符匹配，因此这里为了避免错误，将 B 与 AB 中的 B 对齐, 所以 d2=5.</li>
<li>d2 这里的 k 代表的是匹配的个数</li>
</ul>
</blockquote>
<p><img src="https://ws1.sinaimg.cn/large/006wCagogy1fygiyui3fsj30va0lmtg9.jpg" alt="6"></p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%AE%97%E6%B3%95/" rel="tag">算法</a></li></ul>

    </footer>
  </div>

    
 
   
</article>

    
    <article
  id="post-堆排序算法"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2018/12/22/%E5%A0%86%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/"
    >堆排序算法</a> 
</h2>
 

    </header>
     
    <div class="article-meta">
      <a href="/2018/12/22/%E5%A0%86%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/" class="article-date">
  <time datetime="2018-12-22T11:33:30.000Z" itemprop="datePublished">2018-12-22</time>
</a>    
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h1 id="1-堆排序"><a href="#1-堆排序" class="headerlink" title="1. 堆排序"></a>1. 堆排序</h1><h2 id="1-1-堆的定义"><a href="#1-1-堆的定义" class="headerlink" title="1.1 堆的定义"></a>1.1 堆的定义</h2><blockquote>
<p><strong>堆是一棵二叉树，树中节点包含键，满足下面两个条件</strong>:</p>
</blockquote>
<ul>
<li><strong>树的形状为完全二叉树</strong></li>
<li><strong>父母的优势：每个节点的键都要大于或等于它子女的键</strong></li>
</ul>
<h2 id="1-2-自底向上堆构造算法"><a href="#1-2-自底向上堆构造算法" class="headerlink" title="1.2 自底向上堆构造算法"></a>1.2 自底向上堆构造算法</h2><blockquote>
<p><strong>按照自下而上，从右至左的顺序（最后的父母节点开始，到根为止）检查父母优势条件。如果不满足则调换父子结点的位置</strong>。</p>
</blockquote>
<p><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyfr7woq7xj31090c3gn5.jpg" alt="1"><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyfre6d60lj30zb0byq4h.jpg" alt="2"><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyfrdnjrxyj30z80bmjsw.jpg" alt="3"><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyfrelvx0tj30z60brq4g.jpg" alt="4"></p>
<h2 id="1-3-删除堆中最大的键（即根节点）"><a href="#1-3-删除堆中最大的键（即根节点）" class="headerlink" title="1.3 删除堆中最大的键（即根节点）"></a>1.3 删除堆中最大的键（即根节点）</h2><blockquote>
<p><strong>步骤如下</strong>：</p>
</blockquote>
<ul>
<li><strong>把待删除结点与堆中最后一个键 K 对调。</strong></li>
<li><strong>执行删除操作并把堆的大小减一。</strong></li>
<li><strong>对删除后的堆进行调整直到满足堆的约束条件。</strong></li>
</ul>
<p><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyfro0erzwj311t0kr77e.jpg" alt="5"><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyfroguncmj30yu0m8tam.jpg" alt="6"></p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%AE%97%E6%B3%95/" rel="tag">算法</a></li></ul>

    </footer>
  </div>

    
 
   
</article>

    
    <article
  id="post-快速排序算法图解"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2018/12/22/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E5%9B%BE%E8%A7%A3/"
    >快速排序算法图解</a> 
</h2>
 

    </header>
     
    <div class="article-meta">
      <a href="/2018/12/22/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E5%9B%BE%E8%A7%A3/" class="article-date">
  <time datetime="2018-12-22T06:34:48.000Z" itemprop="datePublished">2018-12-22</time>
</a>    
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h1 id="1-快速排序（过程图解）"><a href="#1-快速排序（过程图解）" class="headerlink" title="1.快速排序（过程图解）"></a>1.快速排序（过程图解）</h1><p>假设我们现在对“6 1 2 7 9 3 4 5 10 8”这个 10 个数进行排序。首先在这个序列中随便找一个数作为基准数（不要被这个名词吓到了，就是一个用来参照的数，待会你就知道它用来做啥的了）。为了方便，就让第一个数 6 作为基准数吧。接下来，需要将这个序列中所有比基准数大的数放在 6 的右边，比基准数小的数放在 6 的左边，类似下面这种排列。<br>3 1 2 5 4 6 9 7 10 8</p>
<p>在初始状态下，数字 6 在序列的第 1 位。我们的目标是将 6 挪到序列中间的某个位置，假设这个位置是 k。现在就需要寻找这个 k，并且以第 k 位为分界点，左边的数都小于等于 6，右边的数都大于等于 6。想一想，你有办法可以做到这点吗？</p>
<p>给你一个提示吧。请回忆一下冒泡排序，是如何通过“交换”，一步步让每个数归位的。此时你也可以通过“交换”的方法来达到目的。具体是如何一步步交换呢？怎样交换才既方便又节省时间呢？先别急着往下看，拿出笔来，在纸上画画看。我高中时第一次学习冒泡排序算法的时候，就觉得冒泡排序很浪费时间，每次都只能对相邻的两个数进行比较，这显然太不合理了。于是我就想了一个办法，后来才知道原来这就是“快速排序”，请允许我小小的自恋一下(^o^)。</p>
<p>方法其实很简单：分别从初始序列“6 1 2 7 9 3 4 5 10 8”两端开始“探测”。先从右往左找一个小于 6 的数，再从左往右找一个大于 6 的数，然后交换他们。这里可以用两个变量 i 和 j，分别指向序列最左边和最右边。我们为这两个变量起个好听的名字“哨兵 i”和“哨兵 j”。刚开始的时候让哨兵 i 指向序列的最左边（即 i=1），指向数字 6。让哨兵 j 指向序列的最右边（即 j=10），指向数字 8。</p>
<p><img src="http://bbs.ahalei.com/data/attachment/forum/201402/26/094811yilrz1tkzkvlrriz.png" alt="1"></p>
<p>首先哨兵 j 开始出动。因为此处设置的基准数是最左边的数，所以需要让哨兵 j 先出动，这一点非常重要（请自己想一想为什么）。哨兵 j 一步一步地向左挪动（即 j–），直到找到一个小于 6 的数停下来。接下来哨兵 i 再一步一步向右挪动（即 i++），直到找到一个数大于 6 的数停下来。最后哨兵 j 停在了数字 5 面前，哨兵 i 停在了数字 7 面前。</p>
<p><img src="http://bbs.ahalei.com/data/attachment/forum/201402/26/095430axy0qkhxxkktkktk.png" alt="2"></p>
<p><img src="http://bbs.ahalei.com/data/attachment/forum/201402/26/095437kdandfxhbtokk2qh.png" alt="3"></p>
<p>现在交换哨兵 i 和哨兵 j 所指向的元素的值。交换之后的序列如下。</p>
<pre><code>6  1  2  5  9 3  4  7  10  8</code></pre>
<p><img src="http://bbs.ahalei.com/data/attachment/forum/201402/26/095448k1kevwlz41373e7k.png" alt="4"></p>
<p>到此，第一次交换结束。接下来开始哨兵 j 继续向左挪动（再友情提醒，每次必须是哨兵 j 先出发）。他发现了 4（比基准数 6 要小，满足要求）之后停了下来。哨兵 i 也继续向右挪动的，他发现了 9（比基准数 6 要大，满足要求）之后停了下来。此时再次进行交换，交换之后的序列如下。</p>
<pre><code>6  1  2 5  4  3  9  7 10  8</code></pre>
<p>第二次交换结束，“探测”继续。哨兵 j 继续向左挪动，他发现了 3（比基准数 6 要小，满足要求）之后又停了下来。哨兵 i 继续向右移动，糟啦！此时哨兵 i 和哨兵 j 相遇了，哨兵 i 和哨兵 j 都走到 3 面前。说明此时“探测”结束。我们将基准数 6 和 3 进行交换。交换之后的序列如下。</p>
<pre><code>3  1 2  5  4  6  9 7  10  8</code></pre>
<p><img src="http://bbs.ahalei.com/data/attachment/forum/201402/26/095506uz7e1uuukcblhkxv.png" alt="a"></p>
<p><img src="http://bbs.ahalei.com/data/attachment/forum/201402/26/095514cag5fumuqqg5jnsw.png" alt="a"></p>
<p><img src="http://bbs.ahalei.com/data/attachment/forum/201402/26/095530e0jf6p0y6aaaw2ir.png" alt="a"></p>
<p>到此第一轮“探测”真正结束。此时以基准数 6 为分界点，6 左边的数都小于等于 6，6 右边的数都大于等于 6。回顾一下刚才的过程，其实哨兵 j 的使命就是要找小于基准数的数，而哨兵 i 的使命就是要找大于基准数的数，直到 i 和 j 碰头为止。<br>OK，解释完毕。现在基准数 6 已经归位，它正好处在序列的第 6 位。此时我们已经将原来的序列，以 6 为分界点拆分成了两个序列，左边的序列是“3 1 2 5 4”，右边的序列是“9 7 10 8”。接下来还需要分别处理这两个序列。因为 6 左边和右边的序列目前都还是很混乱的。不过不要紧，我们已经掌握了方法，接下来只要模拟刚才的方法分别处理 6 左边和右边的序列即可。现在先来处理 6 左边的序列现吧。</p>
<p>左边的序列是“3 1 2 5 4”。请将这个序列以 3 为基准数进行调整，使得 3 左边的数都小于等于 3，3 右边的数都大于等于 3。好了开始动笔吧。</p>
<p>如果你模拟的没有错，调整完毕之后的序列的顺序应该是。</p>
<pre><code>2  1  3  5  4</code></pre>
<p>OK，现在 3 已经归位。接下来需要处理 3 左边的序列“2 1”和右边的序列“5 4”。对序列“2 1”以 2 为基准数进行调整，处理完毕之后的序列为“1 2”，到此 2 已经归位。序列“1”只有一个数，也不需要进行任何处理。至此我们对序列“2 1”已全部处理完毕，得到序列是“1 2”。序列“5 4”的处理也仿照此方法，最后得到的序列如下。</p>
<pre><code>1  2  3 4  5  6 9  7  10  8</code></pre>
<p>对于序列“9 7 10 8”也模拟刚才的过程，直到不可拆分出新的子序列为止。最终将会得到这样的序列，如下。</p>
<pre><code>1  2  3 4  5  6  7  8 9  10</code></pre>
<p>到此，排序完全结束。细心的同学可能已经发现，快速排序的每一轮处理其实就是将这一轮的基准数归位，直到所有的数都归位为止，排序就结束了。下面上个霸气的图来描述下整个算法的处理过程。<br><img src="http://bbs.ahalei.com/data/attachment/forum/201402/25/232129ogop8gk0r8y7l70k.png" alt="aa"></p>
<p>快速排序之所比较快，因为相比冒泡排序，每次交换是跳跃式的。每次排序的时候设置一个基准点，将小于等于基准点的数全部放到基准点的左边，将大于等于基准点的数全部放到基准点的右边。这样在每次交换的时候就不会像冒泡排序一样每次只能在相邻的数之间进行交换，交换的距离就大的多了。因此总的比较和交换次数就少了，速度自然就提高了。当然在最坏的情况下，仍可能是相邻的两个数进行了交换。因此快速排序的最差时间复杂度和冒泡排序是一样的都是 O(N2)，它的平均时间复杂度为 O(NlogN)。</p>
<h1 id="2-代码"><a href="#2-代码" class="headerlink" title="2.代码"></a>2.代码</h1><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># <span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="keyword">int</span> a[<span class="number">101</span>],n;<span class="comment">//定义全局变量，这两个变量需要在子函数中使用</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">quicksort</span><span class="params">(<span class="keyword">int</span> left, <span class="keyword">int</span> right)</span> </span>&#123;</span><br><span class="line">	<span class="keyword">int</span> i, j, t, temp;</span><br><span class="line">	<span class="keyword">if</span>(left &gt; right)</span><br><span class="line">		<span class="keyword">return</span>;</span><br><span class="line">    temp = a[left]; <span class="comment">//temp中存的就是基准数</span></span><br><span class="line">    i = left;</span><br><span class="line">    j = right;</span><br><span class="line">    <span class="keyword">while</span>(i != j) &#123; <span class="comment">//顺序很重要，要先从右边开始找</span></span><br><span class="line">    	<span class="keyword">while</span>(a[j] &gt;= temp &amp;&amp; i &lt; j)</span><br><span class="line">    		j--;</span><br><span class="line">    	<span class="keyword">while</span>(a[i] &lt;= temp &amp;&amp; i &lt; j)<span class="comment">//再找右边的</span></span><br><span class="line">    		i++;</span><br><span class="line">    	<span class="keyword">if</span>(i &lt; j)<span class="comment">//交换两个数在数组中的位置</span></span><br><span class="line">    	&#123;</span><br><span class="line">    		t = a[i];</span><br><span class="line">    		a[i] = a[j];</span><br><span class="line">    		a[j] = t;</span><br><span class="line">    	&#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//最终将基准数归位</span></span><br><span class="line">    a[left] = a[i];</span><br><span class="line">    a[i] = temp;</span><br><span class="line">    quicksort(left, i<span class="number">-1</span>);<span class="comment">//继续处理左边的，这里是一个递归的过程</span></span><br><span class="line">    quicksort(i+<span class="number">1</span>, right);<span class="comment">//继续处理右边的 ，这里是一个递归的过程</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">	<span class="keyword">int</span> i;</span><br><span class="line">    <span class="comment">//读入数据</span></span><br><span class="line">	<span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>, &amp;n);</span><br><span class="line">	<span class="keyword">for</span>(i = <span class="number">1</span>; i &lt;= n; i++)</span><br><span class="line">		<span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>, &amp;a[i]);</span><br><span class="line">    quicksort(<span class="number">1</span>, n); <span class="comment">//快速排序调用</span></span><br><span class="line">    <span class="comment">//输出排序后的结果</span></span><br><span class="line">    <span class="keyword">for</span>(i = <span class="number">1</span>; i &lt; n; i++)</span><br><span class="line">    	<span class="built_in">printf</span>(<span class="string">&quot;%d &quot;</span>, a[i]);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;%d\n&quot;</span>, a[n]);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%AE%97%E6%B3%95/" rel="tag">算法</a></li></ul>

    </footer>
  </div>

    
 
   
</article>

    
  </article>
  

  
  <nav class="page-nav">
    
    <a class="extend prev" rel="prev" href="/">上一页</a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/3/">下一页</a>
  </nav>
  
</section>
</div>

      <footer class="footer">
  <div class="outer">
    <ul>
      <li>
        Copyrights &copy;
        2020
        <i class="ri-heart-fill heart_icon"></i> John Doe
      </li>
    </ul>
    <ul>
      <li>
        
        
        
        Powered by <a href="https://hexo.io" target="_blank">Hexo</a>
        <span class="division">|</span>
        Theme - <a href="https://github.com/Shen-Yu/hexo-theme-ayer" target="_blank">Ayer</a>
        
      </li>
    </ul>
    <ul>
      <li>
        
        
        <span>
  <span><i class="ri-user-3-fill"></i>Visitors:<span id="busuanzi_value_site_uv"></span></s>
  <span class="division">|</span>
  <span><i class="ri-eye-fill"></i>Views:<span id="busuanzi_value_page_pv"></span></span>
</span>
        
      </li>
    </ul>
    <ul>
      
    </ul>
    <ul>
      
    </ul>
    <ul>
      <li>
        <!-- cnzz统计 -->
        
        <script type="text/javascript" src='https://s9.cnzz.com/z_stat.php?id=1278069914&amp;web_id=1278069914'></script>
        
      </li>
    </ul>
  </div>
</footer>
      <div class="float_btns">
        <div class="totop" id="totop">
  <i class="ri-arrow-up-line"></i>
</div>

<div class="todark" id="todark">
  <i class="ri-moon-line"></i>
</div>

      </div>
    </main>
    <aside class="sidebar on">
      <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
    <a href="/"><img src="/images/logo.png" alt="Z2WNB"></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">主页</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/archives">归档</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/categories">分类</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags">标签</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/%E6%97%85%E8%A1%8C/">旅行</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/photos">摄影</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/friends">友链</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/about">关于我</a>
    </li>
    
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      
      <a class="nav-item-link nav-item-search"  title="Search">
        <i class="ri-search-line"></i>
      </a>
      
      
      <a class="nav-item-link" target="_blank" href="/atom.xml" title="RSS Feed">
        <i class="ri-rss-line"></i>
      </a>
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
    </aside>
    <script>
      if (window.matchMedia("(max-width: 768px)").matches) {
        document.querySelector('.content').classList.remove('on');
        document.querySelector('.sidebar').classList.remove('on');
      }
    </script>
    <div id="mask"></div>

<!-- #reward -->
<div id="reward">
  <span class="close"><i class="ri-close-line"></i></span>
  <p class="reward-p"><i class="ri-cup-line"></i>请我喝杯咖啡吧~</p>
  <div class="reward-box">
    
    <div class="reward-item">
      <img class="reward-img" src="/images/alipay.jpg">
      <span class="reward-type">支付宝</span>
    </div>
    
    
    <div class="reward-item">
      <img class="reward-img" src="/images/wechat.jpg">
      <span class="reward-type">微信</span>
    </div>
    
  </div>
</div>
    
<script src="/js/jquery-2.0.3.min.js"></script>


<script src="/js/lazyload.min.js"></script>

<!-- Tocbot -->

<script src="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.js"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.css">
<script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js"></script>

<script src="/dist/main.js"></script>

<!-- ImageViewer -->

<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css">
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"></script>

<script>
    function viewer_init() {
        let pswpElement = document.querySelectorAll('.pswp')[0];
        let $imgArr = document.querySelectorAll(('.article-entry img:not(.reward-img)'))

        $imgArr.forEach(($em, i) => {
            $em.onclick = () => {
                // slider展开状态
                // todo: 这样不好，后面改成状态
                if (document.querySelector('.left-col.show')) return
                let items = []
                $imgArr.forEach(($em2, i2) => {
                    let img = $em2.getAttribute('data-idx', i2)
                    let src = $em2.getAttribute('data-target') || $em2.getAttribute('src')
                    let title = $em2.getAttribute('alt')
                    // 获得原图尺寸
                    const image = new Image()
                    image.src = src
                    items.push({
                        src: src,
                        w: image.width || $em2.width,
                        h: image.height || $em2.height,
                        title: title
                    })
                })
                var gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, {
                    index: parseInt(i)
                });
                gallery.init()
            }
        })
    }
    viewer_init()
</script>

<!-- MathJax -->

<!-- Katex -->

<!-- busuanzi  -->


<script src="/js/busuanzi-2.3.pure.min.js"></script>


<!-- ClickLove -->

<!-- ClickBoom1 -->

<!-- ClickBoom2 -->


<script src="/js/clickBoom2.js"></script>


<!-- CodeCopy -->


<link rel="stylesheet" href="/css/clipboard.css">

<script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script>
<script>
  function wait(callback, seconds) {
    var timelag = null;
    timelag = window.setTimeout(callback, seconds);
  }
  !function (e, t, a) {
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '<i class="ri-file-copy-2-line"></i><span>COPY</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      $(".article pre code").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        let $btn = $(e.trigger);
        $btn.addClass('copied');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-checkbox-circle-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPIED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-checkbox-circle-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
      clipboard.on('error', function(e) {
        e.clearSelection();
        let $btn = $(e.trigger);
        $btn.addClass('copy-failed');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-time-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPY FAILED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-time-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
    }
    initCopyCode();
  }(window, document);
</script>


<!-- CanvasBackground -->


<script src="/js/dz.js"></script>



    
  </div>
</body>

</html>